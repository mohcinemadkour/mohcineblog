<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mohcine Madkour, Big Data Architectures and more">


        <title>Transfer learning in NLP Part I : Pre-trained embeddings // Mohcine Madkour // Big Data Architectures and more</title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/mohcine-madkour.html" title="See posts by Mohcine Madkour">
                        <img class="avatar" alt="Mohcine Madkour" src="http://www.gravatar.com/avatar/ae08847efc1a85b710f326eb8ee2e907">
                </a>
                <h2 class="article-info">Mohcine Madkour</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>Sun 07 July 2019</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Transfer learning in NLP Part I : Pre-trained embeddings</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="../../../../tag/nlp/">NLP</a>
                                <a class="post-category" href="../../../../tag/july-2019/">July 2019</a>
                                <a class="post-category" href="../../../../tag/transfer-learning/">Transfer learning</a>
                        </p>
                </header>
            </section>
            <p>We are going to build some PyTorch models that are commonly used for text classification.  We also need to build out some infrastructure to run these models.</p>
<p>Once we have the models and the boilerplate stuff out of the way, we can see the impact of pre-trained embeddings for classification tasks. Pre-training methods like word2vec are context-limited language models whose goal is to predict a word given a fixed context, or a fixed context given a word. Pre-trained embeddings are particularly useful for smaller datasets.</p>
<p>Most of this code is inspired or derived from <a href="https://github.com/dpressel/baseline/">Baseline</a> (Pressel et al, 2018), an open source project for building and evaluating NLP models across a variety of NLP tasks.  For this tutorial, we will only concern ourselves with Text Classification using a few useful models.</p>
<h2>Word Embeddings in NLP</h2>
<p>We start our models with what are called "one-hot" vectors.  This is notionally a sparse vector with length <code>|V|</code> where V is our vocabulary, and where only the word representated at this temporal location is a 1.  The rest are zeros.</p>
<p><img alt="onehot" src="https://www.tensorflow.org/images/feature_columns/categorical_column_with_vocabulary.jpg"></p>
<p>These vectors are not truly represented as a vector, but as an array of indices (in PyTorch, they are <code>torch.LongTensor</code>s), one for each word's index in the vocab.  This representation is not particularly helpful in DNNs since we want continuous representations for each word.</p>
<p><img alt="indices" src="https://www.tensorflow.org/images/feature_columns/categorical_column_with_identity.jpg"></p>
<p>The general idea of an embedding is that we want to project from a large one-hot vector to a compact, distributed representation with smaller dimensionality.  We can look at this as a matrix multiply between a one-hot vector <code>|V|</code> and a weight matrix to a lower dimension of size <code>|D|</code>.  Since only a single vector value in the one-hot vector is on at a time, this matrix multiply is simplified to an address lookup in that matrix.</p>
<p><img alt="LUT" src="https://cdn-images-1.medium.com/max/800/1*fZj1Hk1mhS5pIMv3ZrpLYw.png"></p>
<p>In PyTorch, this is called an <code>nn.Embedding</code>.  In fact, in Torch7, this was called a <code>nn.LookupTable</code> which may have actually been a better name, but which seems to have fallen out of favor in DNN toolkits.  In this tutorial we are going to refer to multiple types of embeddings, and in this case, we are referring to word vectors, which are typically lookup table embeddings.</p>
<p>Embeddings make up lowest layer of a typical DNN for text and we will feed their output to some pooling mechanism yielding a fixed length representation, followed by some number of fully connected layers.</p>
<h3>Pre-training with Word2Vec</h3>
<p>There has been a large amount of research that has gone into building distributed representations for words through pre-training. Some widely used algorithms in NLP include Word2Vec, GloVe and fastText.  For instance, word2vec is actually 2 different algorithms with 2 different objectives.  They can be thought of a fixed context window non-causal LMs, but they are shallow models and extremely fast to train</p>
<p><img alt="word2vec" src="https://deeplearning4j.org/img/word2vec_diagrams.png"></p>
<ul>
<li><strong>CBOW objective</strong> given all words in a fixed context window except the middle word, predict the middle word</li>
<li><strong>SkipGram objective</strong>: given a word in a fixed context window, predict all other words in that window</li>
</ul>
<p>Once we have trained these models, the learned distributed representation matrix can be plugged right in as our embedding weights and this often improves the model significantly.</p>
<p>Before we begin, we will download some data that can be used for our experiments</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">dropbox</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="mi">7j</span><span class="n">yi4pi894bh2qh</span><span class="o">/</span><span class="n">sst2</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">tar</span> <span class="o">-</span><span class="n">xzf</span> <span class="s1">&#39;sst2.tar.gz?dl=1&#39;</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">dropbox</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="mi">08</span><span class="n">km2ean8bkt7p3</span><span class="o">/</span><span class="n">trec</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">tar</span> <span class="o">-</span><span class="n">xzf</span> <span class="s1">&#39;trec.tar.gz?dl=1&#39;</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">dropbox</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="mi">699</span><span class="n">kgut7hdb5tg9</span><span class="o">/</span><span class="n">GoogleNews</span><span class="o">-</span><span class="n">vectors</span><span class="o">-</span><span class="n">negative300</span><span class="o">.</span><span class="n">bin</span><span class="o">.</span><span class="n">gz</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">mv</span> <span class="s1">&#39;GoogleNews-vectors-negative300.bin.gz?dl=1&#39;</span> <span class="n">GoogleNews</span><span class="o">-</span><span class="n">vectors</span><span class="o">-</span><span class="n">negative300</span><span class="o">.</span><span class="n">bin</span><span class="o">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">gunzip</span> <span class="n">GoogleNews</span><span class="o">-</span><span class="n">vectors</span><span class="o">-</span><span class="n">negative300</span><span class="o">.</span><span class="n">bin</span><span class="o">.</span><span class="n">gz</span>
</pre></div>


<div class="highlight"><pre><span></span>--2019-07-08 00:32:45--  https://www.dropbox.com/s/7jyi4pi894bh2qh/sst2.tar.gz?dl=1
Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6018:1::a27d:301, 162.125.3.1
Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6018:1::a27d:301|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: /s/dl/7jyi4pi894bh2qh/sst2.tar.gz [following]
--2019-07-08 00:32:45--  https://www.dropbox.com/s/dl/7jyi4pi894bh2qh/sst2.tar.gz
Reusing existing connection to [www.dropbox.com]:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com/cd/0/get/AkRLWd3A_OI7KBUn-VSMqeMgKz-UOPUTcEizbIpo0QNYHdzxKIhKRXKRLpO-YhOpuodmoJ-CvdeBgkzejDwGRE8E1NXaoVBNTDdXo9QK8pvgBw/file?dl=1# [following]
--2019-07-08 00:32:45--  https://uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com/cd/0/get/AkRLWd3A_OI7KBUn-VSMqeMgKz-UOPUTcEizbIpo0QNYHdzxKIhKRXKRLpO-YhOpuodmoJ-CvdeBgkzejDwGRE8E1NXaoVBNTDdXo9QK8pvgBw/file?dl=1
Resolving uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com (uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com)... 2620:100:6018:6::a27d:306, 162.125.3.6
Connecting to uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com (uc3565d8839a10c5d53bd45de20c.dl.dropboxusercontent.com)|2620:100:6018:6::a27d:306|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1759259 (1.7M) [application/binary]
Saving to: ‘sst2.tar.gz?dl=1’

sst2.tar.gz?dl=1    100%[===================&amp;gt;]   1.68M   935KB/s    in 1.8s

2019-07-08 00:32:48 (935 KB/s) - ‘sst2.tar.gz?dl=1’ saved [1759259/1759259]

--2019-07-08 00:32:48--  https://www.dropbox.com/s/08km2ean8bkt7p3/trec.tar.gz?dl=1
Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6018:1::a27d:301, 162.125.3.1
Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6018:1::a27d:301|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: /s/dl/08km2ean8bkt7p3/trec.tar.gz [following]
--2019-07-08 00:32:49--  https://www.dropbox.com/s/dl/08km2ean8bkt7p3/trec.tar.gz
Reusing existing connection to [www.dropbox.com]:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com/cd/0/get/AkQGUYOHicMExjYIVGDFLGzAAyWTvTdF_5mVfLAakOE9VuAsn4ssIZVNEt087E2oL-OZHEquUp8ywHeCeAdyvinMSnPa6b4OIdJXfSFfS4E6lg/file?dl=1# [following]
--2019-07-08 00:32:49--  https://uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com/cd/0/get/AkQGUYOHicMExjYIVGDFLGzAAyWTvTdF_5mVfLAakOE9VuAsn4ssIZVNEt087E2oL-OZHEquUp8ywHeCeAdyvinMSnPa6b4OIdJXfSFfS4E6lg/file?dl=1
Resolving uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com (uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com)... 2620:100:6018:6::a27d:306, 162.125.3.6
Connecting to uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com (uc249811a6e442bf7f679c39dfd1.dl.dropboxusercontent.com)|2620:100:6018:6::a27d:306|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 117253 (115K) [application/binary]
Saving to: ‘trec.tar.gz?dl=1’

trec.tar.gz?dl=1    100%[===================&amp;gt;] 114.50K  --.-KB/s    in 0.09s

2019-07-08 00:32:49 (1.21 MB/s) - ‘trec.tar.gz?dl=1’ saved [117253/117253]

--2019-07-08 00:32:50--  https://www.dropbox.com/s/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz?dl=1
Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6018:1::a27d:301, 162.125.3.1
Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6018:1::a27d:301|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: /s/dl/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz [following]
--2019-07-08 00:32:50--  https://www.dropbox.com/s/dl/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz
Reusing existing connection to [www.dropbox.com]:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com/cd/0/get/AkS8j2aeKHnhjxuH51sfVvN05jWUSJ6vP1i3_w4HSpcVFrf5oepeKw4n0BDXSQDZ_2yw0ksJFfFhmwpCT-EJF7kCiqMW3-8eAClkpqgkWkXXVw/file?dl=1# [following]
--2019-07-08 00:32:50--  https://uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com/cd/0/get/AkS8j2aeKHnhjxuH51sfVvN05jWUSJ6vP1i3_w4HSpcVFrf5oepeKw4n0BDXSQDZ_2yw0ksJFfFhmwpCT-EJF7kCiqMW3-8eAClkpqgkWkXXVw/file?dl=1
Resolving uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com (uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com)... 2620:100:6018:6::a27d:306, 162.125.3.6
Connecting to uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com (uc63bc9bed52962b811b5cd41c55.dl.dropboxusercontent.com)|2620:100:6018:6::a27d:306|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1743563840 (1.6G) [application/binary]
Saving to: ‘GoogleNews-vectors-negative300.bin.gz?dl=1’

GoogleNews-vectors-  12%[=&amp;gt;                  ] 209.10M   708KB/s    eta 24m 28s
</pre></div>


<h2>First, lets do some fun stuff</h2>
<p>We will start by building out some models that we will reuse later in the tutorial.  First, we will build a convolutional neural network (CNN) that can classify text. Basically CNNs learn a kernel that can be used to filter images or text.  An example of 2D filtering*:</p>
<p><img alt="2D filtering" src="https://cdn-images-1.medium.com/max/1600/0*9J3MK1gd2zrFDzDN.gif"></p>
<p>In the case of text filtering, we have a one-dimensional filter operation like this*:</p>
<p><img alt="1D filtering" src="http://cs231n.github.io/assets/cnn/stride.jpeg"></p>
<p>This type of model has been used often in text, including by <a href="https://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf">Collobert et al 2011</a>, but we will implement a multiple parallel filter variation of this introduced by <a href="https://www.aclweb.org/anthology/D14-1181">Kim 2014</a>.</p>
<h3>Convolutional Neural Network for Text Classification</h3>
<p>We are using PyTorch, so every layer we have is going to inherit <code>nn.Module</code>.</p>
<h4>Convolutions (actually cross correlations)</h4>
<p>The first characteristic of this model is that we will have multiple convolutional filter lengths, and some number of filters associated with each length.  For each filter of length <code>K</code> convolved with a signal of length <code>T</code>, the output signal will be <code>T - K + 1</code>.  To handle the ends of the signal where the filter is hanging off (e.g. centered at 0), we will add some zero-padding.  So if we have a filter of length <code>K=3</code>, we want to zero-pad the temporal signal by a single pad value on both ends of the signal.</p>
<p>We are going to support multiple parallel filters, so we can add a <code>torch.nn.Conv1d</code> for each filter length, followed by a <code>torch.nn.ReLU</code> activation layer.  Since we have more than one of these, we will create a <code>nn.ModuleList</code> to track them.  When we call <code>forward()</code>, the data will be oriented as $$B \times C \times T$$ where <code>B</code> is the batch size,  <code>C</code> is the number of hidden units and <code>T</code> is the temporal length of the vector.</p>
<h4>Pooling</h4>
<p>Both of the papers mentioned above do max-over-time pooling over the features.  For each feature map in the vector, we simply select the maximum value for that feature map and concatenate all of these together.  Our $$B \times C \times T$$ vector is then going to be reduced along the time dimension to $$B \times C$$</p>
<p>*Images courtesy of http://cs231n.github.io/convolutional-networks/</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ParallelConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dims</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">convs</span> <span class="o">=</span> <span class="p">[]</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">filters</span><span class="p">])</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">filter_length</span><span class="p">,</span> <span class="n">output_dims</span><span class="p">)</span> <span class="ow">in</span> <span class="n">filters</span><span class="p">:</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">filter_length</span><span class="o">//</span><span class="mi">2</span>
            <span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">input_dims</span><span class="p">,</span> <span class="n">output_dims</span><span class="p">,</span> <span class="n">filter_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">pad</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>
        <span class="c1"># Add the module so its managed correctly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">convs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_bct</span><span class="p">):</span>
        <span class="n">mots</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">:</span>
            <span class="c1"># In Conv1d, data BxCxT, max over time</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">input_bct</span><span class="p">)</span>
            <span class="n">mot</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">mots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mot</span><span class="p">)</span>
        <span class="n">mots</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mots</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_drop</span><span class="p">(</span><span class="n">mots</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ConvClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">embed_dims</span><span class="p">,</span>
                 <span class="n">filters</span><span class="o">=</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)],</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">ParallelConv</span><span class="p">(</span><span class="n">embed_dims</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="n">input_units</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">output_dims</span>
        <span class="n">output_units</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">output_dims</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
            <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_units</span><span class="p">,</span> <span class="n">h</span><span class="p">)))</span>
            <span class="n">input_units</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">output_units</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">sequence</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">one_hots</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">one_hots</span><span class="p">))</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<h3>LSTM Model</h3>
<p>Our second model that we will explore uses Long Short-Term Memory (LSTM) units, which are a form of Recurrent Neural Networks.  These models tend to perform extremely well on NLP tasks.  Text classification is a simple case, where we give our inputs and take the final LSTM output as a form of pooling.  That looks like the <strong>Many-to-One</strong> image in this taxonomy from <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">Andrej Karpathy's 2015 blog post on using RNNs for character-level language modeling</a></p>
<p><img alt="Many-to-one LSTM" src="https://karpathy.github.io/assets/rnn/diags.jpeg"></p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LSTMClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">embed_dims</span><span class="p">,</span> <span class="n">rnn_units</span><span class="p">,</span> <span class="n">rnn_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dims</span><span class="p">,</span>
                                 <span class="n">rnn_units</span><span class="p">,</span>
                                 <span class="n">rnn_layers</span><span class="p">,</span>
                                 <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                                 <span class="n">bidirectional</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                 <span class="n">batch_first</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">)</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">input_units</span> <span class="o">=</span> <span class="n">rnn_units</span>
        <span class="n">output_units</span> <span class="o">=</span> <span class="n">rnn_units</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
            <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_units</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
            <span class="n">input_units</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">output_units</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">sequence</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">one_hots</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">one_hots</span><span class="p">))</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">packed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<h2>Training our model</h2>
<p>To set our model up for training (and evaluation), we need a loss function, some metrics, and an optimizer, along with some training data.</p>
<h3>Defining Metrics</h3>
<p>For classification problems, most things we would like to know can be defined in terms of a confusion matrix.</p>
<p><img alt="Confusion Matrix" src="https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png"></p>
<p>The class below implements a confusion matrix and provides metrics associated using it.  This implementation is taken from verbatim from Baseline (https://github.com/dpressel/baseline/blob/master/python/baseline/confusion.py)</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ConfusionMatrix</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Confusion matrix with metrics</span>

<span class="sd">    This class accumulates classification output, and tracks it in a confusion matrix.</span>
<span class="sd">    Metrics are available that use the confusion matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor with input labels</span>

<span class="sd">        :param labels: Either a dictionary (`k=int,v=str`) or an array of labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">nc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nc</span><span class="p">,</span> <span class="n">nc</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a single value to the confusion matrix based off `truth` and `guess`</span>

<span class="sd">        :param truth: The real `y` value (or ground truth label)</span>
<span class="sd">        :param guess: The guess for `y` value (or assertion)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)):</span>
                <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:{width}d}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfile</span><span class="p">):</span>
        <span class="n">ordered_fieldnames</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="n">l</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">])</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">outfile</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">dw</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">ordered_fieldnames</span><span class="p">)</span>
            <span class="n">dw</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">):</span>
                <span class="n">row_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
                <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]})</span>
                <span class="n">dw</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">*=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_correct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the diagonals of the confusion matrix</span>

<span class="sd">        :return: (``int``) Number of correct classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_total</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get total classifications</span>

<span class="sd">        :return: (``int``) total classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_acc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the accuracy</span>

<span class="sd">        :return: (``float``) accuracy</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_correct</span><span class="p">())</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the recall</span>

<span class="sd">        :return: (``float``) recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the precision</span>
<span class="sd">        :return: (``float``) precision</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_mean_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean precision across labels</span>

<span class="sd">        :return: (``float``) mean precision</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_mean_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean recall across labels</span>

<span class="sd">        :return: (``float``) mean recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_macro_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the macro F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) macro F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_class_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span>

        <span class="n">b</span> <span class="o">=</span> <span class="n">beta</span><span class="o">*</span><span class="n">beta</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get 2 class F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) 2-class F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_all_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Make a map of metrics suitable for reporting, keyed by metric name</span>

<span class="sd">        :return: (``dict``) Map of metrics keyed by metric names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()}</span>
        <span class="c1"># If 2 class, assume second class is positive AKA 1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;macro_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_macro_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">add_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a batch of data to the confusion matrix</span>

<span class="sd">        :param truth: The truth tensor</span>
<span class="sd">        :param guess: The guess tensor</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span><span class="p">)</span>
</pre></div>


<p>Our <code>Trainer</code> is simple, but it gets the job done.  We will use PyTorch's <code>DataLoader</code> to feed our batches to the trainer.  The <code>run()</code> method cycles a single epoch. 
For every batch, we will do a stochastic gradient minibatch update, and we return the loss and the predictions and ground truth back to the <code>run()</code> method for tabulation</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span> 
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>       
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">loss_value</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span><span class="p">)</span>
        <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>
</pre></div>


<p>After training a epoch, we would like to test the validation performance.  Our evaluator class is similar to our <code>Trainer</code>, but it doesnt update our model -- it just gives us a way to evaluate the model on data</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Evaluator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>
</pre></div>


<p>We can encapsulate training multiple epochs and testing in a single function.   The best model is defined in terms of some metric -- here accuracy, and we only save the checkpoints when we improve on the model.  This is called early stopping, and is particularly helpful on smaller datasets</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">()</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;EPOCH {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;=================================&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;New best model {:.2f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()))</span>
            <span class="n">best_acc</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">))</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Final result&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>
</pre></div>


<h3>A Reader for our Data</h3>
<p>We need a reader to load our data from files and put it into a <code>Dataset</code>.</p>
<p>The reader needs to perform a few steps</p>
<ul>
<li><strong>read in sentences and labels</strong>: it should convert the sentences into tokens and record a vocabulary of the labels</li>
<li><strong>vectorize tokens</strong>: it should convert tokens into tensors that comprise rows in our <code>TensorDataset</code></li>
<li><strong>tabulate the vocabulary</strong>: if no vectorizer is provided, we need to build a vocab of attested words.  If a vectorizer is provided upfront, we dont need this step</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">whitespace_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 

<span class="k">def</span> <span class="nf">sst2_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">REPLACE</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;&#39;s&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;s &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ve&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ve &quot;</span><span class="p">,</span>
                <span class="s2">&quot;n&#39;t&quot;</span><span class="p">:</span> <span class="s2">&quot; n&#39;t &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;re&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;re &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;d&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;d &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ll&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ll &quot;</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="p">:</span> <span class="s2">&quot; , &quot;</span><span class="p">,</span>
                <span class="s2">&quot;!&quot;</span><span class="p">:</span> <span class="s2">&quot; ! &quot;</span><span class="p">,</span>
                <span class="p">}</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^A-Za-z0-9(),!?\&#39;\`]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">REPLACE</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>


<span class="k">class</span> <span class="nc">Reader</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">tokenizer</span><span class="o">=</span><span class="n">sst2_tokenizer</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="o">=</span> <span class="n">lowercase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">build_vocab</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="k">if</span> <span class="n">vectorizer</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">file_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                    <span class="n">y</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cnt</span><span class="p">:</span> <span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_freq</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">alpha</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alpha</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDataset</span><span class="p">:</span>
        <span class="n">label2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label2index</span><span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
                <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec</span><span class="p">))</span>
                <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">lengths_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">lengths_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
</pre></div>


<h3>Pre-trained Embeddings</h3>
<p>We would like to investigate how pre-training embeddings helps our models improve.  To do this, we need a mechanism to load in pre-trained embeddings and convert them into PyTorch's <code>nn.Embedding</code> object.  Specifically, we wish to support <code>word2vec</code>, <code>GloVe</code> and <code>fastText</code> embeddings. Rest-assured, these are simple file formats, and you do not need any 3rd party dependencies to read them in!  We will do it by hand.</p>
<p>For binary files, the first line contains 2 numbers delimited by a space.  The first number is the vocab size and the second is the embedding dimension.  We then read each line, splitting it by a space and reading the first portion as the vocabulary (token) and the second portion as a binary vector.</p>
<p>For text files, the first line may contain 2 numbers as in the binary file, but for <code>GloVe</code> files, this is omitted.  We can check if the first line contains the dimensions, and if it doesnt, we can just read in the first vector to figure out its dimension (again its space delimited, but the vector is also space delimited, so we split along the first space to find the token).</p>
<p>Notice that in this code, we have already created an alphabet that we will pass in for each key, so if that word is present in the embedding file, we will use its value, otherwise, we will initialize the vector randomly.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">init_embeddings</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">unif</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">unif</span><span class="p">,</span> <span class="n">unif</span><span class="p">,</span> <span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">EmbeddingsReader</span><span class="p">:</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_text</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">unif</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>

        <span class="k">with</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> &quot;</span><span class="p">)</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># fastText style</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="n">weight</span> <span class="o">=</span> <span class="n">init_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">unif</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="c1"># glove style</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">weight</span> <span class="o">=</span> <span class="n">init_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">unif</span><span class="p">)</span>
                <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                    <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                    <span class="n">weight</span><span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">=</span> <span class="n">vec</span>
        <span class="k">if</span> <span class="s1">&#39;[PAD]&#39;</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="n">weight</span><span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">embeddings</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_binary</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">unif</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">read_word</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>

            <span class="n">s</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">()</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">while</span> <span class="n">ch</span> <span class="o">!=</span> <span class="sa">b</span><span class="s1">&#39; &#39;</span><span class="p">:</span>
                <span class="n">s</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span>
                <span class="n">ch</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
            <span class="c1"># Only strip out normal space and \n not other spaces which are words.</span>
            <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39; </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">header</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
            <span class="n">file_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">header</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">init_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">unif</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;[PAD]&#39;</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                <span class="n">weight</span><span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">width</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">embed_dim</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">file_vocab_size</span><span class="p">):</span>
                <span class="n">word</span> <span class="o">=</span> <span class="n">read_word</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                    <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                    <span class="n">weight</span><span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">=</span> <span class="n">vec</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">embeddings</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">embed_dim</span>
</pre></div>


<h3>Now to run some stuff!</h3>
<p>We did a lot of work to set things up, but its pretty boilerplate and we will reuse a lot of it.  So far, we made 2 classifiers we can run along with code to train and evaluate our models, and a reader to load our data.</p>
<div class="highlight"><pre><span></span><span class="n">BASE</span> <span class="o">=</span> <span class="s1">&#39;sst2&#39;</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;stsa.binary.phrases.train&#39;</span><span class="p">)</span>
<span class="n">VALID</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;stsa.binary.dev&#39;</span><span class="p">)</span>
<span class="n">TEST</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;stsa.binary.test&#39;</span><span class="p">)</span>
<span class="n">PRETRAINED_EMBEDDINGS_FILE</span> <span class="o">=</span> <span class="s1">&#39;GoogleNews-vectors-negative300.bin&#39;</span>
</pre></div>


<p>Lets read in our datasets:</p>
<div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">Reader</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">VALID</span><span class="p">,</span> <span class="n">TEST</span><span class="p">,))</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">)</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">VALID</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TEST</span><span class="p">)</span>
</pre></div>


<h2>Model trained with randomly initialized embeddings</h2>
<p>First, we are going to train a model without any pretrained embeddings for 10 epochs.  During training, we will see the training and validation performance, and after the final epoch, we will see the results from the best model trained on these epochs. </p>
<div class="highlight"><pre><span></span><span class="n">embed_dim</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">)</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">ConvClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">)</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Model has 5442302 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.5926248359558738, &#39;precision&#39;: 0.6179160630500119, &#39;recall&#39;: 0.6762583118388982, &#39;f1&#39;: 0.6457721335924437}
Validation Results
{&#39;acc&#39;: 0.7110091743119266, &#39;precision&#39;: 0.7622950819672131, &#39;recall&#39;: 0.6283783783783784, &#39;f1&#39;: 0.6888888888888889}
New best model 0.71
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.6340224269435168, &#39;precision&#39;: 0.6503253333333333, &#39;recall&#39;: 0.7213611301734542, &#39;f1&#39;: 0.6840038593578207}
Validation Results
{&#39;acc&#39;: 0.6089449541284404, &#39;precision&#39;: 0.5695006747638327, &#39;recall&#39;: 0.9504504504504504, &#39;f1&#39;: 0.7122362869198312}
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.6637647639713621, &#39;precision&#39;: 0.6763477437133999, &#39;recall&#39;: 0.7433919401784236, &#39;f1&#39;: 0.7082868319298364}
Validation Results
{&#39;acc&#39;: 0.7144495412844036, &#39;precision&#39;: 0.7506426735218509, &#39;recall&#39;: 0.6576576576576577, &#39;f1&#39;: 0.7010804321728692}
New best model 0.71
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.6873481373682775, &#39;precision&#39;: 0.6971548679277991, &#39;recall&#39;: 0.7613289476797842, &#39;f1&#39;: 0.7278300606279975}
Validation Results
{&#39;acc&#39;: 0.7075688073394495, &#39;precision&#39;: 0.6556836902800659, &#39;recall&#39;: 0.8963963963963963, &#39;f1&#39;: 0.7573739295908659}
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.7016800717246398, &#39;precision&#39;: 0.7109843018933928, &#39;recall&#39;: 0.7695165526870016, &#39;f1&#39;: 0.7390933781833471}
Validation Results
{&#39;acc&#39;: 0.6490825688073395, &#39;precision&#39;: 0.597457627118644, &#39;recall&#39;: 0.9527027027027027, &#39;f1&#39;: 0.734375}
EPOCH 6
=================================
Training Results
{&#39;acc&#39;: 0.7181819363054014, &#39;precision&#39;: 0.7250941083778342, &#39;recall&#39;: 0.783998674838496, &#39;f1&#39;: 0.7533967777512478}
Validation Results
{&#39;acc&#39;: 0.7591743119266054, &#39;precision&#39;: 0.7378048780487805, &#39;recall&#39;: 0.8175675675675675, &#39;f1&#39;: 0.7756410256410255}
New best model 0.76
EPOCH 7
=================================
Training Results
{&#39;acc&#39;: 0.7320201140837567, &#39;precision&#39;: 0.7382341929658423, &#39;recall&#39;: 0.7932274781703306, &#39;f1&#39;: 0.7647434581251569}
Validation Results
{&#39;acc&#39;: 0.7431192660550459, &#39;precision&#39;: 0.7370689655172413, &#39;recall&#39;: 0.7702702702702703, &#39;f1&#39;: 0.7533039647577091}
EPOCH 8
=================================
Training Results
{&#39;acc&#39;: 0.7397253154194982, &#39;precision&#39;: 0.7452230704735008, &#39;recall&#39;: 0.7992380321351664, &#39;f1&#39;: 0.7712860095226134}
Validation Results
{&#39;acc&#39;: 0.6788990825688074, &#39;precision&#39;: 0.6209439528023599, &#39;recall&#39;: 0.9481981981981982, &#39;f1&#39;: 0.7504456327985739}
EPOCH 9
=================================
Training Results
{&#39;acc&#39;: 0.7485089850703603, &#39;precision&#39;: 0.7541725852272727, &#39;recall&#39;: 0.8040890697839513, &#39;f1&#39;: 0.7783313290958025}
Validation Results
{&#39;acc&#39;: 0.7545871559633027, &#39;precision&#39;: 0.7281746031746031, &#39;recall&#39;: 0.8265765765765766, &#39;f1&#39;: 0.7742616033755274}
EPOCH 10
=================================
Training Results
{&#39;acc&#39;: 0.7572016995621159, &#39;precision&#39;: 0.7618233111935491, &#39;recall&#39;: 0.8115431032442794, &#39;f1&#39;: 0.7858976121728768}
Validation Results
{&#39;acc&#39;: 0.7591743119266054, &#39;precision&#39;: 0.7303149606299213, &#39;recall&#39;: 0.8355855855855856, &#39;f1&#39;: 0.7794117647058825}
Final result
{&#39;acc&#39;: 0.7391543108182317, &#39;precision&#39;: 0.728421052631579, &#39;recall&#39;: 0.7612761276127613, &#39;f1&#39;: 0.7444862829478214}





0.7391543108182317
</pre></div>


<p>Yikes, thats not very encouraging!  What about our LSTM?</p>
<div class="highlight"><pre><span></span><span class="n">embed_dim</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">)</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">LSTMClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  &quot;num_layers={}&quot;.format(dropout, num_layers))


Model has 5342502 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.6416496667143099, &#39;precision&#39;: 0.648109286089027, &#39;recall&#39;: 0.7600511133722994, &#39;f1&#39;: 0.6996307873269656}
Validation Results
{&#39;acc&#39;: 0.7488532110091743, &#39;precision&#39;: 0.7300613496932515, &#39;recall&#39;: 0.8040540540540541, &#39;f1&#39;: 0.765273311897106}
New best model 0.75
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.7467158690765453, &#39;precision&#39;: 0.7576038743550285, &#39;recall&#39;: 0.7921862798457133, &#39;f1&#39;: 0.7745092368734602}
Validation Results
{&#39;acc&#39;: 0.7786697247706422, &#39;precision&#39;: 0.747534516765286, &#39;recall&#39;: 0.8536036036036037, &#39;f1&#39;: 0.7970557308096741}
New best model 0.78
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.7794467327607489, &#39;precision&#39;: 0.7900387712496272, &#39;recall&#39;: 0.8149033342009986, &#39;f1&#39;: 0.8022784456248252}
Validation Results
{&#39;acc&#39;: 0.783256880733945, &#39;precision&#39;: 0.7958236658932715, &#39;recall&#39;: 0.7725225225225225, &#39;f1&#39;: 0.7839999999999999}
New best model 0.78
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.7937786671171113, &#39;precision&#39;: 0.8048943938623654, &#39;recall&#39;: 0.8242267919259803, &#39;f1&#39;: 0.8144458863830334}
Validation Results
{&#39;acc&#39;: 0.7901376146788991, &#39;precision&#39;: 0.7713097713097713, &#39;recall&#39;: 0.8355855855855856, &#39;f1&#39;: 0.8021621621621621}
New best model 0.79
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.8033159652291421, &#39;precision&#39;: 0.814348632359759, &#39;recall&#39;: 0.8313258714120069, &#39;f1&#39;: 0.8227496809096125}
Validation Results
{&#39;acc&#39;: 0.7878440366972477, &#39;precision&#39;: 0.8018648018648019, &#39;recall&#39;: 0.7747747747747747, &#39;f1&#39;: 0.7880870561282932}
EPOCH 6
=================================
Training Results
{&#39;acc&#39;: 0.8122165772274269, &#39;precision&#39;: 0.8227892183038098, &#39;recall&#39;: 0.8386379232826143, &#39;f1&#39;: 0.8306379787184175}
Validation Results
{&#39;acc&#39;: 0.7889908256880734, &#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.7612612612612613, &#39;f1&#39;: 0.786046511627907}
EPOCH 7
=================================
Training Results
{&#39;acc&#39;: 0.8170501942542326, &#39;precision&#39;: 0.8279907814791536, &#39;recall&#39;: 0.841666863863319, &#39;f1&#39;: 0.8347728126173487}
Validation Results
{&#39;acc&#39;: 0.8027522935779816, &#39;precision&#39;: 0.7995594713656388, &#39;recall&#39;: 0.8175675675675675, &#39;f1&#39;: 0.8084632516703786}
New best model 0.80
EPOCH 8
=================================
Training Results
{&#39;acc&#39;: 0.8234690297683243, &#39;precision&#39;: 0.8332597224482206, &#39;recall&#39;: 0.8482453441870371, &#39;f1&#39;: 0.8406857571706653}
Validation Results
{&#39;acc&#39;: 0.7924311926605505, &#39;precision&#39;: 0.8065268065268065, &#39;recall&#39;: 0.7792792792792793, &#39;f1&#39;: 0.7926689576174113}
EPOCH 9
=================================
Training Results
{&#39;acc&#39;: 0.824742401995816, &#39;precision&#39;: 0.8359920588578769, &#39;recall&#39;: 0.846991173477839, &#39;f1&#39;: 0.8414556738839128}
Validation Results
{&#39;acc&#39;: 0.7981651376146789, &#39;precision&#39;: 0.8116279069767441, &#39;recall&#39;: 0.786036036036036, &#39;f1&#39;: 0.7986270022883294}
EPOCH 10
=================================
Training Results
{&#39;acc&#39;: 0.8271332233209028, &#39;precision&#39;: 0.8384886956115125, &#39;recall&#39;: 0.8486476253579119, &#39;f1&#39;: 0.8435375749735388}
Validation Results
{&#39;acc&#39;: 0.7993119266055045, &#39;precision&#39;: 0.799554565701559, &#39;recall&#39;: 0.8085585585585585, &#39;f1&#39;: 0.8040313549832027}
Final result
{&#39;acc&#39;: 0.8050521691378364, &#39;precision&#39;: 0.7991360691144709, &#39;recall&#39;: 0.8140814081408141, &#39;f1&#39;: 0.8065395095367847}





0.8050521691378364
</pre></div>


<h2>Same model with pre-trained word embeddings</h2>
<p>The models below are identical to the ones above, the only difference is that we are going to initialize the embeddings using our previously defined <code>EmbeddingsReader</code>.  First lets take a look at our CNN model again.  Notice we only run 5 epochs here instead of 10!</p>
<div class="highlight"><pre><span></span><span class="n">embeddings</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">EmbeddingsReader</span><span class="o">.</span><span class="n">from_binary</span><span class="p">(</span><span class="n">PRETRAINED_EMBEDDINGS_FILE</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">ConvClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">)</span>
<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead


Model has 5442302 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.8329153727212484, &#39;precision&#39;: 0.8410831129054712, &#39;recall&#39;: 0.8577817742965995, &#39;f1&#39;: 0.8493503754817998}
Validation Results
{&#39;acc&#39;: 0.8268348623853211, &#39;precision&#39;: 0.9080779944289693, &#39;recall&#39;: 0.7342342342342343, &#39;f1&#39;: 0.8119551681195517}
New best model 0.83
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.8798742220085498, &#39;precision&#39;: 0.8858578775128565, &#39;recall&#39;: 0.8967793842731726, &#39;f1&#39;: 0.8912851750373358}
Validation Results
{&#39;acc&#39;: 0.8474770642201835, &#39;precision&#39;: 0.8373101952277657, &#39;recall&#39;: 0.8693693693693694, &#39;f1&#39;: 0.8530386740331491}
New best model 0.85
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.8955834773456686, &#39;precision&#39;: 0.9008221873462791, &#39;recall&#39;: 0.9100309993137556, &#39;f1&#39;: 0.9054031783402}
Validation Results
{&#39;acc&#39;: 0.8486238532110092, &#39;precision&#39;: 0.8436123348017621, &#39;recall&#39;: 0.8626126126126126, &#39;f1&#39;: 0.8530066815144767}
New best model 0.85
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.9059523654838165, &#39;precision&#39;: 0.9103606664948091, &#39;recall&#39;: 0.9192361390473035, &#39;f1&#39;: 0.91477687507359}
Validation Results
{&#39;acc&#39;: 0.841743119266055, &#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.7657657657657657, &#39;f1&#39;: 0.8312958435207825}
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.9139694130793519, &#39;precision&#39;: 0.9181293410925474, &#39;recall&#39;: 0.9258856101658818, &#39;f1&#39;: 0.9219911634756995}
Validation Results
{&#39;acc&#39;: 0.8428899082568807, &#39;precision&#39;: 0.851258581235698, &#39;recall&#39;: 0.8378378378378378, &#39;f1&#39;: 0.844494892167991}
Final result
{&#39;acc&#39;: 0.8725974739154311, &#39;precision&#39;: 0.8537095088819227, &#39;recall&#39;: 0.8987898789878987, &#39;f1&#39;: 0.8756698821007501}





0.8725974739154311
</pre></div>


<p>Much better!  And now the LSTM!</p>
<div class="highlight"><pre><span></span><span class="n">model</span>  <span class="o">=</span> <span class="n">LSTMClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  &quot;num_layers={}&quot;.format(dropout, num_layers))


Model has 5342502 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.870012084042567, &#39;precision&#39;: 0.8834494400722794, &#39;recall&#39;: 0.8792683215409736, &#39;f1&#39;: 0.8813539220569748}
Validation Results
{&#39;acc&#39;: 0.8371559633027523, &#39;precision&#39;: 0.8081632653061225, &#39;recall&#39;: 0.8918918918918919, &#39;f1&#39;: 0.8479657387580299}
New best model 0.84
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.904562050908902, &#39;precision&#39;: 0.9189545934530094, &#39;recall&#39;: 0.9061028419981543, &#39;f1&#39;: 0.9124834677755669}
Validation Results
{&#39;acc&#39;: 0.8646788990825688, &#39;precision&#39;: 0.9137055837563451, &#39;recall&#39;: 0.8108108108108109, &#39;f1&#39;: 0.8591885441527446}
New best model 0.86
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.9171658372422395, &#39;precision&#39;: 0.9286806517895542, &#39;recall&#39;: 0.9197804018078989, &#39;f1&#39;: 0.9242090996635478}
Validation Results
{&#39;acc&#39;: 0.8600917431192661, &#39;precision&#39;: 0.8340248962655602, &#39;recall&#39;: 0.9054054054054054, &#39;f1&#39;: 0.8682505399568036}
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.9252738399968815, &#39;precision&#39;: 0.9348261076703192, &#39;recall&#39;: 0.9286542511654322, &#39;f1&#39;: 0.9317299588076782}
Validation Results
{&#39;acc&#39;: 0.856651376146789, &#39;precision&#39;: 0.8444924406047516, &#39;recall&#39;: 0.8806306306306306, &#39;f1&#39;: 0.8621830209481808}
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.9308091111082236, &#39;precision&#39;: 0.9387294497766796, &#39;recall&#39;: 0.9350197591045695, &#39;f1&#39;: 0.9368709321762635}
Validation Results
{&#39;acc&#39;: 0.8635321100917431, &#39;precision&#39;: 0.9156010230179028, &#39;recall&#39;: 0.8063063063063063, &#39;f1&#39;: 0.8574850299401198}
Final result
{&#39;acc&#39;: 0.8802855573860516, &#39;precision&#39;: 0.9157641395908543, &#39;recall&#39;: 0.8371837183718371, &#39;f1&#39;: 0.8747126436781609}





0.8802855573860516
</pre></div>


<h4>A quick note about these models on this data</h4>
<p>Both of these models are surprisingly strong baselines and do fairly well on this dataset averaged over many runs.  Even with only 2-5 epochs of data it is quite common to see scores higher than in the Kim 2014 paper.</p>
<h2>Conclusions</h2>
<h3>Its not hard to get good performance with a Deep Learning model for Text Classification</h3>
<p>We saw above how to get good results on the SST-2 dataset using fairly simple deep learning models, even with very few training epochs.  This behavior is not limited to a single dataset -- these results have been shown over and over.  Also, using PyTorch, we were able to code an entire pipeline in this minimalistic notebook.</p>
<h3>Pre-trained embeddings often help</h3>
<p>We can see that pre-trained embeddings can have a massive impact on the performance of our models, especially for smaller datasets.  The <code>word2vec</code> algorithm caused an explosion in the NLP community -- even though pre-training embeddings had been widely studied prior to that work, the results were reliable and fast.  <code>GloVe</code> and <code>fastText</code> embeddings came shortly thereafter, and all 3 models are in quite common use today.  The code above can load any of these flavors of embeddings and incorporate them into downstream models for large improvements.</p>
<p>For large datasets, like those used in Language Modeling and Neural Machine Translation, models are typically trained from random embeddings, which are sufficient in those cases.</p>
<h3>Incorporating pre-trained embeddings into your model is simple</h3>
<p>The file formats are very simple to read and can be incorporated with only a few lines of code.  In some cases, memory-mapping the file can increase the loading speed.  This is implemented in <a href="https://github.com/dpressel/baseline/">Baseline</a></p>
<h3>Some Further Resources</h3>
<ul>
<li><a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks, Karpathy, 2015</a></li>
<li>Tensorflow tutorial for word2vec: https://www.tensorflow.org/tutorials/representation/word2vec</li>
<li>Tensorflow docs on feature columns (for images above): https://www.tensorflow.org/guide/feature_columns</li>
<li>Xin Rong, wrote some amazing software to visualize word embeddings and the training process.  Sadly, Xin is no longer with us -- he was a great researcher and an awesome guy.  We miss him.</li>
<li>https://ronxin.github.io/wevi/</li>
<li>Accompanying talk from a2-dlearn 2015: https://www.youtube.com/channel/UCVdeq2cIxnujw2kTdzg2N5g</li>
<li>https://ronxin.github.io/lamvi/dist/#model=word2vec&amp;backend=browser&amp;query_in=darcy&amp;query_out=G_bennet,B_circumstances</li>
<li>Accompanying paper for Lamvi <a href="http://www.cond.org/ICML16_NeuralVis.pdf">Visual Tools for Debugging Neural Language Models, Rong &amp; Adar, 2016</a></li>
</ul>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "leafyleap-2"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Mohcine Madkour &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>