<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mohcine Madkour, Big Data Architectures and more">


        <title>Transfer learning in NLP Part II : Contextualized embeddings // Mohcine Madkour // Big Data Architectures and more</title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/mohcine-madkour.html" title="See posts by Mohcine Madkour">
                        <img class="avatar" alt="Mohcine Madkour" src="http://www.gravatar.com/avatar/ae08847efc1a85b710f326eb8ee2e907">
                </a>
                <h2 class="article-info">Mohcine Madkour</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>Sun 07 July 2019</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Transfer learning in NLP Part II : Contextualized embeddings</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="../../../../tag/nlp/">NLP</a>
                                <a class="post-category" href="../../../../tag/july-2019/">July 2019</a>
                                <a class="post-category" href="../../../../tag/transfer-learning/">Transfer learning</a>
                                <a class="post-category" href="../../../../tag/context-vectors/">Context vectors</a>
                        </p>
                </header>
            </section>
            <p>In this section, we are going to learn how to train an LSTM-based word-level language model.  Then we will take load a pre-trained langage model checkpoint and use everything below the output layers as the lower layers of our previously defined classification model.  We dont really need to change anything else, we just need to pass this whole network as the <code>embedding</code> parameter to the model.</p>
<h2>LSTM Language Models</h2>
<p>We are going to quickly build an LSTM language model so that we can see how the training works.  For both our objectives and our metrics, we are interested in the perplexity, which is the exponentiated cross-entropy loss.</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">research</span><span class="o">.</span><span class="n">metamind</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">wikitext</span><span class="o">/</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>
</pre></div>


<div class="highlight"><pre><span></span>--2019-06-30 19:10:48--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip
Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.134.253
Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.134.253|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4475746 (4.3M) [application/zip]
Saving to: ‘wikitext-2-v1.zip.5’

wikitext-2-v1.zip.5 100%[===================&amp;gt;]   4.27M  18.2MB/s    in 0.2s

2019-06-30 19:10:49 (18.2 MB/s) - ‘wikitext-2-v1.zip.5’ saved [4475746/4475746]

Archive:  wikitext-2-v1.zip
replace wikitext-2/wiki.test.tokens? [y]es, [n]o, [A]ll, [N]one, [r]ename:
</pre></div>


<p>Our LSTM model will be a word-based model.  We will have a randomly trained embedding to start and we will put each output timestep through our LSTM blocks and then project to the output vocabulary size. At every step of training, we will detach our hidden states, preventing full backpropagation, but we will initialize the new batch from our old hidden state.  We will also create a function that resets the hidden state, which we will use at the start of each epoch to zero out the hidden states.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">class</span> <span class="nc">LSTMLanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span>
                                 <span class="n">hidden_dim</span><span class="p">,</span>
                                 <span class="n">layers</span><span class="p">,</span>
                                 <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                                 <span class="n">bidirectional</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                 <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="c1"># Tie weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">.</span><span class="n">weight</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">decoded</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">decoded</span><span class="p">),</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batchsz</span><span class="p">):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">data</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">batchsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">batchsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()))</span>
</pre></div>


<p>Our dataset reader will read in a sequence of words and vectorize them.  We would like this to be a long sequence of text (like maybe a book), and we will read this in contiguously.  Our task is to learn to predict the next word, so we will end up using this sequence for input and output</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">WordDatasetReader</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Provide a base-class to do operations to read words to tensors</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nctx</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">=</span> <span class="n">nctx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="k">if</span> <span class="n">vectorizer</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>

    <span class="k">def</span> <span class="nf">build_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

        <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">file</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span><span class="p">[</span><span class="nb">file</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">split_sentence</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span><span class="p">[</span><span class="nb">file</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_sentence</span><span class="p">)</span>
                    <span class="n">sentences</span> <span class="o">+=</span> <span class="n">split_sentence</span>
                <span class="n">x</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cnt</span><span class="p">:</span> <span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_freq</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">alpha</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alpha</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">load_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>

        <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">sentences</span> <span class="o">+=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_features</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="n">rest</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">batch_size</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">rest</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span>
        <span class="c1"># if num_examples is divisible by batchsz * nctx (equivalent to rest is divisible by nctx), we</span>
        <span class="c1"># have a problem. reduce rest in that case.</span>

        <span class="k">if</span> <span class="n">rest</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">rest</span> <span class="o">=</span> <span class="n">rest</span><span class="o">-</span><span class="mi">1</span>
        <span class="n">trunc</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">rest</span>

        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">trunc</span><span class="p">)</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x_tensor</span>
</pre></div>


<p>This class will keep track of our running average as we go so we dont have to remember to average things in our loops</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Average</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;:f&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">=</span> <span class="n">fmt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fmtstr</span> <span class="o">=</span> <span class="s1">&#39;{name} {val&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">+</span> <span class="s1">&#39;} ({avg&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmt</span> <span class="o">+</span> <span class="s1">&#39;})&#39;</span>
        <span class="k">return</span> <span class="n">fmtstr</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</pre></div>


<p>We are going to train on batches of contiguous text. Our batches will have been pre-created by the loader.  Each batch will be <code>BxT</code> where <code>B</code> is the batch size we specified, and <code>T</code> is the number of backprop steps through time.</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SequenceCriterion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate some loss over a sequence.</span>

<span class="sd">        :param inputs: torch.FloatTensor, [B, .., C] The scores from the model. Batch First</span>
<span class="sd">        :param targets: torch.LongTensor, The labels.</span>

<span class="sd">        :returns: torch.FloatTensor, The loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_sz</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">crit</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">total_sz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">total_sz</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="k">class</span> <span class="nc">LMTrainer</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">nctx</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">=</span> <span class="n">nctx</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">Average</span><span class="p">(</span><span class="s1">&#39;average_train_loss&#39;</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[:,</span><span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="p">]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[:,</span> <span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="o">+</span><span class="mi">1</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">c</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">avg_loss</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>

        <span class="c1"># How much time elapsed in minutes</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span>
        <span class="n">train_token_loss</span> <span class="o">=</span> <span class="n">avg_loss</span><span class="o">.</span><span class="n">avg</span>
        <span class="n">train_token_ppl</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">train_token_loss</span><span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train_elapsed_min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;average_train_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_token_loss</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train_ppl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_token_ppl</span>
        <span class="k">return</span> <span class="n">metrics</span>

<span class="k">class</span> <span class="nc">LMEvaluator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nctx</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">=</span> <span class="n">nctx</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="n">avg_valid_loss</span> <span class="o">=</span> <span class="n">Average</span><span class="p">(</span><span class="s1">&#39;average_valid_loss&#39;</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">valid_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>

            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">valid_data</span><span class="p">[:,</span><span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="p">]</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">valid_data</span><span class="p">[:,</span> <span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span><span class="o">+</span><span class="mi">1</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nctx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

                <span class="n">logits</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">avg_valid_loss</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">valid_token_loss</span> <span class="o">=</span> <span class="n">avg_valid_loss</span><span class="o">.</span><span class="n">avg</span>
        <span class="n">valid_token_ppl</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">valid_token_loss</span><span class="p">)</span>

        <span class="n">elapsed</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;valid_elapsed_min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>

        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;average_valid_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">valid_token_loss</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;average_valid_word_ppl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">valid_token_ppl</span>
        <span class="k">return</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">fit_lm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">nctx</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">):</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">SequenceCriterion</span><span class="p">()</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">LMTrainer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">nctx</span><span class="p">)</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">LMEvaluator</span><span class="p">(</span><span class="n">nctx</span><span class="p">)</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;EPOCH {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;=================================&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training Results&#39;</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation Results&#39;</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>


<p>Now we will train it on <a href="https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/">Wikitext-2, Merity et al. 2016</a>.  We will use 35 steps of backprop.</p>
<div class="highlight"><pre><span></span><span class="n">BASE</span> <span class="o">=</span> <span class="s1">&#39;wikitext-2&#39;</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;wiki.train.tokens&#39;</span><span class="p">)</span>
<span class="n">VALID</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;wiki.valid.tokens&#39;</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">nctx</span> <span class="o">=</span> <span class="mi">35</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">WordDatasetReader</span><span class="p">(</span><span class="n">nctx</span><span class="p">)</span>
<span class="n">reader</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,))</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">valid_set</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">VALID</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>


<p>Lets start with 1 epoch</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LSTMLanguageModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">fit_lm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">nctx</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Model has 21274623 parameters


/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;mean&#39; instead.
  warnings.warn(warning.format(ret))


EPOCH 1
=================================
Training Results
average_train_loss 7.130287 (7.630262)
average_train_loss 6.948112 (7.174242)
average_train_loss 6.429612 (6.957250)
average_train_loss 6.706582 (6.817735)
average_train_loss 6.480259 (6.716661)
average_train_loss 6.253604 (6.639940)
average_train_loss 6.250593 (6.584427)
average_train_loss 6.086081 (6.535446)
average_train_loss 6.046218 (6.491021)
average_train_loss 5.840661 (6.455732)
average_train_loss 6.127773 (6.425025)
average_train_loss 5.766460 (6.398616)
average_train_loss 6.137995 (6.376816)
average_train_loss 6.115303 (6.351095)
average_train_loss 6.203366 (6.333509)
average_train_loss 6.009459 (6.318195)
average_train_loss 6.126120 (6.297565)
average_train_loss 5.796104 (6.276726)
average_train_loss 5.737082 (6.260670)
average_train_loss 5.954897 (6.243683)
average_train_loss 5.674878 (6.226430)
average_train_loss 5.613625 (6.207307)
average_train_loss 5.878324 (6.189868)
average_train_loss 5.824322 (6.178013)
average_train_loss 5.932457 (6.164326)
average_train_loss 5.771354 (6.153274)
average_train_loss 5.401644 (6.139012)
average_train_loss 5.825085 (6.124258)
average_train_loss 5.493943 (6.110777)
{&#39;train_elapsed_min&#39;: 2.2767986059188843, &#39;average_train_loss&#39;: 6.0969437521813985, &#39;train_ppl&#39;: 444.4971984264256}
Validation Results
{&#39;valid_elapsed_min&#39;: 0.07908193667729696, &#39;average_valid_loss&#39;: 5.534342344345585, &#39;average_valid_word_ppl&#39;: 253.24118736148796}
</pre></div>


<p>We can sample out of our language model using the code below.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">index2word</span><span class="p">,</span> <span class="n">start_word</span><span class="o">=</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>


    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> 
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_word</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">start_word</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">word_softmax</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">selected</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">word_softmax</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">x</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">index2word</span><span class="p">[</span><span class="n">selected</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
            <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">words</span>

<span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">reader</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">index2word</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>the latter story pass that would be in Park or Ireland . Like Liam Stuart illustrator , NC apologize and livestock ...
</pre></div>


<p>Lets train a few more epochs and try again</p>
<div class="highlight"><pre><span></span><span class="n">fit_lm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;mean&#39; instead.
  warnings.warn(warning.format(ret))


EPOCH 1
=================================
Training Results
average_train_loss 5.888901 (5.598958)
average_train_loss 5.818975 (5.584962)
average_train_loss 5.503317 (5.580568)
average_train_loss 5.877174 (5.584086)
average_train_loss 5.637257 (5.563949)
average_train_loss 5.447403 (5.540543)
average_train_loss 5.460862 (5.531339)
average_train_loss 5.488514 (5.525078)
average_train_loss 5.359737 (5.517013)
average_train_loss 5.121772 (5.509718)
average_train_loss 5.441720 (5.503375)
average_train_loss 5.280029 (5.499962)
average_train_loss 5.543726 (5.500008)
average_train_loss 5.556562 (5.494267)
average_train_loss 5.593565 (5.495319)
average_train_loss 5.347257 (5.496266)
average_train_loss 5.519910 (5.489749)
average_train_loss 5.264927 (5.483263)
average_train_loss 5.207999 (5.481013)
average_train_loss 5.434073 (5.476722)
average_train_loss 5.112748 (5.471222)
average_train_loss 5.142471 (5.463090)
average_train_loss 5.362827 (5.455768)
average_train_loss 5.287307 (5.454580)
average_train_loss 5.420770 (5.449693)
average_train_loss 5.358116 (5.448896)
average_train_loss 5.019379 (5.443910)
average_train_loss 5.375151 (5.437743)
average_train_loss 5.061219 (5.432098)
{&#39;train_elapsed_min&#39;: 2.3279770851135253, &#39;average_train_loss&#39;: 5.425043830046748, &#39;train_ppl&#39;: 227.0212964512552}
Validation Results
{&#39;valid_elapsed_min&#39;: 0.0792834202448527, &#39;average_valid_loss&#39;: 5.2854782812057, &#39;average_valid_word_ppl&#39;: 197.4485968212379}
EPOCH 2
=================================
Training Results
average_train_loss 5.594471 (5.241230)
average_train_loss 5.464106 (5.238882)
average_train_loss 5.156283 (5.241025)
average_train_loss 5.523200 (5.251309)
average_train_loss 5.250049 (5.232446)
average_train_loss 5.129644 (5.205283)
average_train_loss 5.083561 (5.195768)
average_train_loss 5.166030 (5.192733)
average_train_loss 5.086248 (5.188236)
average_train_loss 4.777071 (5.182954)
average_train_loss 5.161200 (5.178061)
average_train_loss 5.008852 (5.176982)
average_train_loss 5.142172 (5.180397)
average_train_loss 5.281511 (5.176891)
average_train_loss 5.325745 (5.180915)
average_train_loss 5.139209 (5.184646)
average_train_loss 5.210761 (5.179825)
average_train_loss 5.041038 (5.176068)
average_train_loss 4.949179 (5.175644)
average_train_loss 5.189332 (5.173076)
average_train_loss 4.856432 (5.168824)
average_train_loss 4.836321 (5.162272)
average_train_loss 5.064670 (5.156098)
average_train_loss 4.960176 (5.156356)
average_train_loss 5.104852 (5.152806)
average_train_loss 5.087171 (5.153634)
average_train_loss 4.799379 (5.150230)
average_train_loss 5.135460 (5.145286)
average_train_loss 4.837797 (5.140926)
{&#39;train_elapsed_min&#39;: 2.3252848744392396, &#39;average_train_loss&#39;: 5.135120418061357, &#39;train_ppl&#39;: 169.88477583838508}
Validation Results
{&#39;valid_elapsed_min&#39;: 0.0793849547704061, &#39;average_valid_loss&#39;: 5.172104538640668, &#39;average_valid_word_ppl&#39;: 176.2854469011485}
EPOCH 3
=================================
Training Results
average_train_loss 5.397759 (5.021339)
average_train_loss 5.223657 (5.019342)
average_train_loss 4.937864 (5.024831)
average_train_loss 5.331026 (5.037493)
average_train_loss 5.013303 (5.017465)
average_train_loss 4.930802 (4.989496)
average_train_loss 4.877040 (4.980525)
average_train_loss 5.008083 (4.979450)
average_train_loss 4.872459 (4.977045)
average_train_loss 4.537238 (4.972334)
average_train_loss 4.895549 (4.967794)
average_train_loss 4.778692 (4.967996)
average_train_loss 4.913031 (4.972698)
average_train_loss 4.998916 (4.970212)
average_train_loss 5.101923 (4.975337)
average_train_loss 4.911569 (4.980182)
average_train_loss 5.020348 (4.975942)
average_train_loss 4.840934 (4.973322)
average_train_loss 4.820501 (4.974319)
average_train_loss 4.994349 (4.972502)
average_train_loss 4.695219 (4.968739)
average_train_loss 4.709369 (4.962705)
average_train_loss 4.882851 (4.957035)
average_train_loss 4.744756 (4.957699)
average_train_loss 4.943813 (4.954420)
average_train_loss 4.885959 (4.955989)
average_train_loss 4.626930 (4.953493)
average_train_loss 4.934981 (4.949243)
average_train_loss 4.673239 (4.945310)
{&#39;train_elapsed_min&#39;: 2.333573551972707, &#39;average_train_loss&#39;: 4.939903614627328, &#39;train_ppl&#39;: 139.75677840163237}
Validation Results
{&#39;valid_elapsed_min&#39;: 0.07996076345443726, &#39;average_valid_loss&#39;: 5.096776191649899, &#39;average_valid_word_ppl&#39;: 163.49398352530844}
</pre></div>


<div class="highlight"><pre><span></span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">reader</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">index2word</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>the Supreme Court did not introduce any contact with its way and Grosser Davies of the chance of the country . ...
</pre></div>


<h2>ELMo</h2>
<p>For the rest of this section, we will focus on ELMo (<a href="https://export.arxiv.org/pdf/1802.05365">Peters et al 2018</a>), a language model with an embedding layer and 2 subsequent LSTM layers.  Actually, at training time, ELMo is basically two LMs -- one working in the forward direction and one working in the backward direction.  The losses for the forward and reverse directions are averaged.  At inference time, the forward and backward layers are aggregated into a single bidirectional representation at each layer.</p>
<p>In our example, we created a word-based LM.  You might have been wondering what to do about words that we havent seen yet -- and that is a valid concern!   Instead of using a word embedding layer like our example above, what if we had a model that used a character compositional approach, taking each character in a word and applying a pooling operation to yield a word representation.  This would mean that the model can handle words that its never seen in the input before.</p>
<p>This is exactly what ELMo does -- its based on the research of <a href="https://arxiv.org/abs/1508.06615">Kim et al. 2015</a>.  </p>
<p>There is a nice <a href="http://www.people.fas.harvard.edu/~yoonkim/data/char-nlm-slides.pdf">slide deck by the authors here</a>, but the key high-level points are listed here:</p>
<h3>Kim Language Model</h3>
<ul>
<li>
<p><strong>Goal</strong>: predict the next word in the sentence (causal LM) but account for unseen words by using a character compositional approach that relies on letters within the pre-segmented words.  This also has the important impact of reducing the number of parameters required in the model drastically over word-level models.</p>
</li>
<li>
<p><strong>Using</strong>: LSTM layers that take in a word representation for each position.  Each word is put in and used to predict the next word over a context</p>
</li>
<li>
<p><strong>The Twist</strong>: use embeddings approach from <a href="http://proceedings.mlr.press/v32/santos14.pdf">dos Santos &amp; Zadrozny 2014</a> to represent words, but add parallel filters as in <a href="https://www.aclweb.org/anthology/D14-1181">Kim 2014</a>.  Also, add highway layers on top of the base model</p>
</li>
</ul>
<h3>ELMo Language Model</h3>
<ul>
<li>
<p><strong>Goal</strong>: predict the next word in the sentence (causal LM) on the forward sequence <strong>and</strong> predict the previous word on the sentence conditioned on the following context.  </p>
</li>
<li>
<p><strong>Using</strong>: LSTM layers as before, but bidirectional, sum the forward and backward loss to make one big loss</p>
</li>
<li>
<p><strong>The Twist</strong> Potentially use all layers of the model (except we dont need head with the big softmax at the end over the words). After the fact, we can freeze our biLM embeddings but still provide useful information by learning a linear combination of the layers during downstream training.  During the biLM training, these scalars dont exist</p>
</li>
</ul>
<h3>ELMo with AllenNLP</h3>
<p>Even though ELMo is just a network like described above, there are a lot of details to getting it set up and reloading the pre-trained checkpoints that are provided, and these details are not really important for demonstration purposes.  So, we will just install <a href="https://github.com/allenai/allennlp">AllenNLP</a> and use it as a contextual embedding layer.</p>
<p>If you are interested in learning more about using ELMo with AllenNLP, they have provided a <a href="https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md">tutorial here</a></p>
<h4>TensorFlow and ELMo</h4>
<p>ELMo was originally trained with TensorFlow.  You can find the code to train and use it in the <a href="https://github.com/allenai/bilm-tf/tree/master/bilm">bilm-tf repository</a></p>
<p>TF-Hub contains the <a href="https://tfhub.dev/google/elmo/2">pre-trained ELMo model</a> and is very easy to integrate if you are using TensorFlow already.  The model takes a sequence of words (mixed-case) as inputs and can just be "glued" in to your existing models as a sub-graph of your own.</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">allennlp</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">Collecting</span> <span class="nt">allennlp</span>
  <span class="nt">Using</span> <span class="nt">cached</span> <span class="nt">https</span><span class="o">://</span><span class="nt">files</span><span class="p">.</span><span class="nc">pythonhosted</span><span class="p">.</span><span class="nc">org</span><span class="o">/</span><span class="nt">packages</span><span class="o">/</span><span class="nt">30</span><span class="o">/</span><span class="nt">8c</span><span class="o">/</span><span class="nt">72b14d20c9cbb0306939ea41109fc599302634fd5c59ccba1a659b7d0360</span><span class="o">/</span><span class="nt">allennlp-0</span><span class="p">.</span><span class="nc">8</span><span class="p">.</span><span class="nc">4-py3-none-any</span><span class="p">.</span><span class="nc">whl</span>
<span class="nt">Collecting</span> <span class="nt">jsonnet</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;=</span><span class="nt">0</span><span class="p">.</span><span class="nc">10</span><span class="p">.</span><span class="nc">0</span><span class="o">;</span> <span class="nt">sys_platform</span> <span class="o">!=</span> <span class="s2">&quot;win32&quot;</span> <span class="o">(</span><span class="nt">from</span> <span class="nt">allennlp</span><span class="o">)</span>
<span class="err"></span><span class="cp">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/a9/a8/adba6cd0f84ee6ab064e7f70cd03a2836cefd2e063fd565180ec13beae93/jsonnet-0.13.0.tar.gz (255kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">256</span><span class="nx">kB</span> <span class="mf">3.4</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hCollecting</span> <span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz</span>
<span class="nx">Collecting</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.6.0</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">133</span><span class="nx">kB</span> <span class="mf">49.5</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">sqlparse</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.4</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.3.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">pytest</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.6.4</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">parsimonious</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Using</span> <span class="nx">cached</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz</span>
<span class="nx">Collecting</span> <span class="nx">conllu</span><span class="o">==</span><span class="mf">0.11</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Using</span> <span class="nx">cached</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl</span>
<span class="nx">Collecting</span> <span class="nx">overrides</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz</span>
<span class="nx">Collecting</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/20/fa/f4b6207d59267da0be60be3df32682d2c7479122c7cb87556bd4412675fe/awscli-1.16.190-py2.py3-none-any.whl (1.7MB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mf">1.7</span><span class="nx">MB</span> <span class="mf">51.2</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.1.4</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">tensorboardX</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.2</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/a2/57/2f0a46538295b8e7f09625da6dd24c23f9d0d7ef119ca1c33528660130d5/tensorboardX-1.7-py2.py3-none-any.whl (238kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">245</span><span class="nx">kB</span> <span class="mf">52.8</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">boto3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.9.175</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">tqdm</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">4.19</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">4.28.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">scipy</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.3.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">requests</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.18</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.21.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">h5py</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.8.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">gevent</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.3.6</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.4.0</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">jsonpickle</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl</span>
<span class="nx">Collecting</span> <span class="nx">flask</span><span class="na">-cors</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.0.7</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">numpy</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.16.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">flask</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.0.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">pytz</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2017.3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2018.9</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">nltk</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.2.5</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">ftfy</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">51</span><span class="nx">kB</span> <span class="mf">26.0</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">editdistance</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.5.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">torch</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.4.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.0</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">word2number</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.1</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip</span>
<span class="nx">Collecting</span> <span class="nx">responses</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.7</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Using</span> <span class="nx">cached</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">matplotlib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.2.3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.0.3</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">flaky</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/ae/09/94d623dda1adacd51722f3e3e0f88ba08dd030ac2b2662bfb4383096340d/flaky-3.6.0-py2.py3-none-any.whl</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">scikit</span><span class="na">-learn</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.21.2</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">unidecode</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">245</span><span class="nx">kB</span> <span class="mf">27.3</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.8.5</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">Jinja2</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.10.1</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">regex</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.6.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">655</span><span class="nx">kB</span> <span class="mf">50.1</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">six</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.10.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.12.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">py</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.5.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.8.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">more</span><span class="na">-itertools</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">4.0.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">7.0.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">setuptools</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">41.0.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">atomicwrites</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.3.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">attrs</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">17.4.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">19.1.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">pluggy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">0.8</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytest</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.7.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">PyYAML</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="o">=</span><span class="mf">5.1</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.10</span><span class="p">;</span> <span class="nx">python_version</span> <span class="o">!=</span> <span class="s2">&quot;2.6&quot;</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.13</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">s3transfer</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">0.3.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.2.1</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">botocore</span><span class="o">==</span><span class="mf">1.12.180</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/3b/27/fa7da6feb20d1dfc0ab562226061b20da2d27ea18ca32dc764fe86704a99/botocore-1.12.180-py2.py3-none-any.whl (5.6MB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mf">5.6</span><span class="nx">MB</span> <span class="mf">35.1</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hCollecting</span> <span class="nx">rsa</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.5.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.1.2</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span>
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">51</span><span class="nx">kB</span> <span class="mf">26.7</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">docutils</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.10</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.14</span><span class="p">)</span>
<span class="nx">Collecting</span> <span class="nx">colorama</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.3.9</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.5</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span>
  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">thinc</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">7.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">7.0.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">7.0.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">blis</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">0.3.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.2.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">cymem</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.0.2</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">jsonschema</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">3.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.6.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.6.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">preshed</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.0.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">srsly</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.0.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.0.7</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">wasabi</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.2.2</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">murmurhash</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.28.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.0.2</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">plac</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.0.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.9.6</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">spacy</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.2</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.9.6</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">protobuf</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.2.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">tensorboardX</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.2</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.7.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">jmespath</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.0.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.7.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.9.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">urllib3</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.25</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.21.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.24.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">idna</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.9</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.8</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">chardet</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">3.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.0.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.0.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">certifi</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2017.4.17</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.18</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2019.6.16</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">greenlet</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.4.14</span><span class="p">;</span> <span class="nx">platform_python_implementation</span> <span class="o">==</span> <span class="s2">&quot;CPython&quot;</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">gevent</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.3.6</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.4.15</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">Werkzeug</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.14</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">flask</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0.2</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.15.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">click</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">5.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">flask</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0.2</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">7.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">itsdangerous</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.24</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">flask</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0.2</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">wcwidth</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">ftfy</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.1.7</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">kiwisolver</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.0.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">matplotlib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.2.3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">cycler</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.10</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">matplotlib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.2.3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.10.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">python</span><span class="na">-dateutil</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">matplotlib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.2.3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.5.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">pyparsing</span><span class="o">!=</span><span class="mf">2.0.4</span><span class="p">,</span><span class="o">!=</span><span class="mf">2.1.2</span><span class="p">,</span><span class="o">!=</span><span class="mf">2.1.6</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">matplotlib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.2.3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.4.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">joblib</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.11</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">scikit</span><span class="na">-learn</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.13.2</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">Pygments</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.1.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">snowballstemmer</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.2.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">sphinxcontrib</span><span class="na">-websupport</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.2</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">packaging</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">19.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">imagesize</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">babel</span><span class="o">!=</span><span class="mf">2.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.7.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">alabaster</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">0.8</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.7</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">sphinx</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.6.5</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.7.12</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">MarkupSafe</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.23</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">Jinja2</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">numpydoc</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.8.0</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">pyasn1</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.1.3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">rsa</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.5.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.1.2</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">awscli</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.11.91</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">allennlp</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.4.5</span><span class="p">)</span>
<span class="nx">Building</span> <span class="nx">wheels</span> <span class="nx">for</span> <span class="nx">collected</span> <span class="nx">packages</span><span class="p">:</span> <span class="nx">jsonnet</span><span class="p">,</span> <span class="nx">numpydoc</span><span class="p">,</span> <span class="nx">parsimonious</span><span class="p">,</span> <span class="nx">overrides</span><span class="p">,</span> <span class="nx">word2number</span><span class="p">,</span> <span class="nx">regex</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">jsonnet</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">1a</span><span class="p">/</span><span class="nx">30</span><span class="p">/</span><span class="nx">ab</span><span class="p">/</span><span class="nx">ae4a57b1df44fa20a531edb9601b27603da8f5336225691f3f</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">numpydoc</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">51</span><span class="p">/</span><span class="nx">30</span><span class="p">/</span><span class="nx">d1</span><span class="p">/</span><span class="nx">92a39ba40f21cb70e53f8af96eb98f002a781843c065406500</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">parsimonious</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">b7</span><span class="p">/</span><span class="nx">8d</span><span class="p">/</span><span class="nx">e7</span><span class="p">/</span><span class="nx">a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">overrides</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">8d</span><span class="p">/</span><span class="nx">52</span><span class="p">/</span><span class="nx">86</span><span class="p">/</span><span class="nx">e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">word2number</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">46</span><span class="p">/</span><span class="nx">2f</span><span class="p">/</span><span class="nx">53</span><span class="p">/</span><span class="nx">5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e</span>
  <span class="nx">Building</span> <span class="nx">wheel</span> <span class="nx">for</span> <span class="nx">regex</span> <span class="p">(</span><span class="nx">setup.py</span><span class="p">)</span> <span class="nx">...</span> <span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span><span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nx">directory</span><span class="p">:</span> <span class="p">/</span><span class="nx">root</span><span class="p">/</span><span class="nx">.cache</span><span class="p">/</span><span class="nx">pip</span><span class="p">/</span><span class="nx">wheels</span><span class="p">/</span><span class="nx">35</span><span class="p">/</span><span class="nx">e4</span><span class="p">/</span><span class="nx">80</span><span class="p">/</span><span class="nx">abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473</span>
<span class="nx">Successfully</span> <span class="nx">built</span> <span class="nx">jsonnet</span> <span class="nx">numpydoc</span> <span class="nx">parsimonious</span> <span class="nx">overrides</span> <span class="nx">word2number</span> <span class="nx">regex</span>
<span class="nx">Installing</span> <span class="nx">collected</span> <span class="nx">packages</span><span class="p">:</span> <span class="nx">jsonnet</span><span class="p">,</span> <span class="nx">numpydoc</span><span class="p">,</span> <span class="nx">regex</span><span class="p">,</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">,</span> <span class="nx">parsimonious</span><span class="p">,</span> <span class="nx">conllu</span><span class="p">,</span> <span class="nx">overrides</span><span class="p">,</span> <span class="nx">botocore</span><span class="p">,</span> <span class="nx">rsa</span><span class="p">,</span> <span class="nx">colorama</span><span class="p">,</span> <span class="nx">awscli</span><span class="p">,</span> <span class="nx">tensorboardX</span><span class="p">,</span> <span class="nx">jsonpickle</span><span class="p">,</span> <span class="nx">flask</span><span class="na">-cors</span><span class="p">,</span> <span class="nx">ftfy</span><span class="p">,</span> <span class="nx">word2number</span><span class="p">,</span> <span class="nx">responses</span><span class="p">,</span> <span class="nx">flaky</span><span class="p">,</span> <span class="nx">unidecode</span><span class="p">,</span> <span class="nx">allennlp</span>
  <span class="nx">Found</span> <span class="nx">existing</span> <span class="nx">installation</span><span class="p">:</span> <span class="nx">botocore</span> <span class="mf">1.12.175</span>
    <span class="nx">Uninstalling</span> <span class="nx">botocore</span><span class="o">-</span><span class="mf">1.12.175</span><span class="p">:</span>
      <span class="nx">Successfully</span> <span class="nx">uninstalled</span> <span class="nx">botocore</span><span class="o">-</span><span class="mf">1.12.175</span>
  <span class="nx">Found</span> <span class="nx">existing</span> <span class="nx">installation</span><span class="p">:</span> <span class="nx">rsa</span> <span class="mf">4.0</span>
    <span class="nx">Uninstalling</span> <span class="nx">rsa</span><span class="o">-</span><span class="mf">4.0</span><span class="p">:</span>
      <span class="nx">Successfully</span> <span class="nx">uninstalled</span> <span class="nx">rsa</span><span class="o">-</span><span class="mf">4.0</span>
<span class="nx">Successfully</span> <span class="nx">installed</span> <span class="nx">allennlp</span><span class="o">-</span><span class="mf">0.8.4</span> <span class="nx">awscli</span><span class="o">-</span><span class="mf">1.16.190</span> <span class="nx">botocore</span><span class="o">-</span><span class="mf">1.12.180</span> <span class="nx">colorama</span><span class="o">-</span><span class="mf">0.3.9</span> <span class="nx">conllu</span><span class="o">-</span><span class="mf">0.11</span> <span class="nx">flaky</span><span class="o">-</span><span class="mf">3.6.0</span> <span class="nx">flask</span><span class="na">-cors</span><span class="o">-</span><span class="mf">3.0.8</span> <span class="nx">ftfy</span><span class="o">-</span><span class="mf">5.5.1</span> <span class="nx">jsonnet</span><span class="o">-</span><span class="mf">0.13.0</span> <span class="nx">jsonpickle</span><span class="o">-</span><span class="mf">1.2</span> <span class="nx">numpydoc</span><span class="o">-</span><span class="mf">0.9.1</span> <span class="nx">overrides</span><span class="o">-</span><span class="mf">1.9</span> <span class="nx">parsimonious</span><span class="o">-</span><span class="mf">0.8.1</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="o">-</span><span class="mf">0.6.2</span> <span class="nx">regex</span><span class="o">-</span><span class="mf">2019.6.8</span> <span class="nx">responses</span><span class="o">-</span><span class="mf">0.10.6</span> <span class="nx">rsa</span><span class="o">-</span><span class="mf">3.4.2</span> <span class="nx">tensorboardX</span><span class="o">-</span><span class="mf">1.7</span> <span class="nx">unidecode</span><span class="o">-</span><span class="mf">1.1.1</span> <span class="nx">word2number</span><span class="o">-</span><span class="mf">1.1</span>
</pre></div>


<h3>Approach</h3>
<p>We will use mostly the same code as in our previous classification experiments.  For brevity, I have compacted it all here and omitted parts that arent required for this section.  For more information, see the previous section.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="k">class</span> <span class="nc">LSTMClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">embed_dims</span><span class="p">,</span> <span class="n">rnn_units</span><span class="p">,</span> <span class="n">rnn_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dims</span><span class="p">,</span>
                                 <span class="n">rnn_units</span><span class="p">,</span>
                                 <span class="n">rnn_layers</span><span class="p">,</span>
                                 <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
                                 <span class="n">bidirectional</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                 <span class="n">batch_first</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">)</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">input_units</span> <span class="o">=</span> <span class="n">rnn_units</span>
        <span class="n">output_units</span> <span class="o">=</span> <span class="n">rnn_units</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
            <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_units</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
            <span class="n">input_units</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">output_units</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">sequence</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">one_hots</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">one_hots</span><span class="p">))</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">packed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ConfusionMatrix</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Confusion matrix with metrics</span>

<span class="sd">    This class accumulates classification output, and tracks it in a confusion matrix.</span>
<span class="sd">    Metrics are available that use the confusion matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor with input labels</span>

<span class="sd">        :param labels: Either a dictionary (`k=int,v=str`) or an array of labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">nc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nc</span><span class="p">,</span> <span class="n">nc</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a single value to the confusion matrix based off `truth` and `guess`</span>

<span class="sd">        :param truth: The real `y` value (or ground truth label)</span>
<span class="sd">        :param guess: The guess for `y` value (or assertion)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)):</span>
                <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:{width}d}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfile</span><span class="p">):</span>
        <span class="n">ordered_fieldnames</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="n">l</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">])</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">outfile</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">dw</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">ordered_fieldnames</span><span class="p">)</span>
            <span class="n">dw</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">):</span>
                <span class="n">row_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
                <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]})</span>
                <span class="n">dw</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">*=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_correct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the diagonals of the confusion matrix</span>

<span class="sd">        :return: (``int``) Number of correct classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_total</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get total classifications</span>

<span class="sd">        :return: (``int``) total classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_acc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the accuracy</span>

<span class="sd">        :return: (``float``) accuracy</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_correct</span><span class="p">())</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the recall</span>

<span class="sd">        :return: (``float``) recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the precision</span>
<span class="sd">        :return: (``float``) precision</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_mean_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean precision across labels</span>

<span class="sd">        :return: (``float``) mean precision</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_mean_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean recall across labels</span>

<span class="sd">        :return: (``float``) mean recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_macro_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the macro F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) macro F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_class_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span>

        <span class="n">b</span> <span class="o">=</span> <span class="n">beta</span><span class="o">*</span><span class="n">beta</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get 2 class F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) 2-class F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_all_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Make a map of metrics suitable for reporting, keyed by metric name</span>

<span class="sd">        :return: (``dict``) Map of metrics keyed by metric names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()}</span>
        <span class="c1"># If 2 class, assume second class is positive AKA 1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;macro_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_macro_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">add_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a batch of data to the confusion matrix</span>

<span class="sd">        :param truth: The truth tensor</span>
<span class="sd">        :param guess: The guess tensor</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span> 
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>       
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">loss_value</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span><span class="p">)</span>
        <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>

<span class="k">class</span> <span class="nc">Evaluator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>

<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">()</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;EPOCH {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;=================================&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;New best model {:.2f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()))</span>
            <span class="n">best_acc</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">))</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Final result&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">whitespace_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 

<span class="k">def</span> <span class="nf">sst2_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">REPLACE</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;&#39;s&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;s &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ve&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ve &quot;</span><span class="p">,</span>
                <span class="s2">&quot;n&#39;t&quot;</span><span class="p">:</span> <span class="s2">&quot; n&#39;t &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;re&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;re &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;d&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;d &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ll&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ll &quot;</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="p">:</span> <span class="s2">&quot; , &quot;</span><span class="p">,</span>
                <span class="s2">&quot;!&quot;</span><span class="p">:</span> <span class="s2">&quot; ! &quot;</span><span class="p">,</span>
                <span class="p">}</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^A-Za-z0-9(),!?\&#39;\`]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">REPLACE</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>


<span class="k">class</span> <span class="nc">Reader</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">tokenizer</span><span class="o">=</span><span class="n">sst2_tokenizer</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="o">=</span> <span class="n">lowercase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">build_vocab</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="k">if</span> <span class="n">vectorizer</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">file_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                    <span class="n">y</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cnt</span><span class="p">:</span> <span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_freq</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">alpha</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alpha</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDataset</span><span class="p">:</span>
        <span class="n">label2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label2index</span><span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
                <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec</span><span class="p">))</span>
                <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">lengths_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">lengths_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
</pre></div>


<h3>The new thing: set up to use ELMo</h3>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">allennlp.modules.elmo</span> <span class="kn">import</span> <span class="n">Elmo</span><span class="p">,</span> <span class="n">batch_to_ids</span>


<span class="k">def</span> <span class="nf">elmo_vectorizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="n">character_ids</span> <span class="o">=</span> <span class="n">batch_to_ids</span><span class="p">([</span><span class="n">sentence</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">character_ids</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ElmoEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options_file</span><span class="p">,</span> <span class="n">weight_file</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">elmo</span> <span class="o">=</span> <span class="n">Elmo</span><span class="p">(</span><span class="n">options_file</span><span class="p">,</span> <span class="n">weight_file</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xch</span><span class="p">):</span>
        <span class="n">elmo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">elmo</span><span class="p">(</span><span class="n">xch</span><span class="p">)</span>
        <span class="n">e1</span><span class="p">,</span> <span class="n">e2</span> <span class="o">=</span> <span class="n">elmo</span><span class="p">[</span><span class="s1">&#39;elmo_representations&#39;</span><span class="p">]</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">elmo</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="p">(</span><span class="n">e1</span> <span class="o">+</span> <span class="n">e2</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span>
</pre></div>


<p>As before, we are going to load up our data with a reader.  This time, though, we will provide a vectorizer for ELMo.  In our simple example <code>Reader</code>, we only allow a single feature as our input vector to our classifier, so we can stop counting up our vocab.  In real life, you probably want to support both word vector features and context vector features so you might want to modify the code to support both.  This is a very common approach -- just using ELMo to augment an existing setup.  Here, we just look at using ELMo features by themselves.</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">dropbox</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="mi">08</span><span class="n">km2ean8bkt7p3</span><span class="o">/</span><span class="n">trec</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">tar</span> <span class="o">-</span><span class="n">xzf</span> <span class="s1">&#39;trec.tar.gz?dl=1&#39;</span>
</pre></div>


<div class="highlight"><pre><span></span>--2019-06-30 19:21:55--  https://www.dropbox.com/s/08km2ean8bkt7p3/trec.tar.gz?dl=1
Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801
Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: /s/dl/08km2ean8bkt7p3/trec.tar.gz [following]
--2019-06-30 19:21:56--  https://www.dropbox.com/s/dl/08km2ean8bkt7p3/trec.tar.gz
Reusing existing connection to www.dropbox.com:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com/cd/0/get/Aj3XoF2sz7098a7ulJjBQP5DA6LkkkTQEAgFciDKPLgTZrHSUdejKQ7f8hkI3LiEt0BP_zf3LYg-ul8IZkevEcRCL4oxvYa8Uw-4SCn9GK2Lqw/file?dl=1# [following]
--2019-06-30 19:21:56--  https://uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com/cd/0/get/Aj3XoF2sz7098a7ulJjBQP5DA6LkkkTQEAgFciDKPLgTZrHSUdejKQ7f8hkI3LiEt0BP_zf3LYg-ul8IZkevEcRCL4oxvYa8Uw-4SCn9GK2Lqw/file?dl=1
Resolving uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com (uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806
Connecting to uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com (uc7fa2ae1930db92d5916f06ba12.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 117253 (115K) [application/binary]
Saving to: ‘trec.tar.gz?dl=1’

trec.tar.gz?dl=1    100%[===================&amp;gt;] 114.50K  --.-KB/s    in 0.07s

2019-06-30 19:21:56 (1.71 MB/s) - ‘trec.tar.gz?dl=1’ saved [117253/117253]
</pre></div>


<p>We will set up our reader slightly differently than in the last experiment.  Here we will use an <code>elmo_vectorizer</code></p>
<div class="highlight"><pre><span></span><span class="n">BASE</span> <span class="o">=</span> <span class="s1">&#39;trec&#39;</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.nodev.utf8&#39;</span><span class="p">)</span>
<span class="n">VALID</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.dev.utf8&#39;</span><span class="p">)</span>
<span class="n">TEST</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.test.utf8&#39;</span><span class="p">)</span>



<span class="n">reader</span> <span class="o">=</span> <span class="n">Reader</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">VALID</span><span class="p">,</span> <span class="n">TEST</span><span class="p">,),</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="n">elmo_vectorizer</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">)</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">VALID</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TEST</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:392: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
</pre></div>


<p>Building the network is basically the same as before, but we are using ELMo instead of word vectors.  The command below will take a few minutes -- this is a much larger (forward) network than before, even though the learnable parameters havent really changed</p>
<div class="highlight"><pre><span></span><span class="n">options_file</span> <span class="o">=</span> <span class="s2">&quot;https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json&quot;</span>
<span class="n">weight_file</span> <span class="o">=</span> <span class="s2">&quot;https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5&quot;</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElmoEmbedding</span><span class="p">(</span><span class="n">options_file</span><span class="p">,</span> <span class="n">weight_file</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LSTMClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embed_dims</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">rnn_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reader</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="nt">336</span><span class="o">/</span><span class="nt">336</span> <span class="cp">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">192499.13</span><span class="nx">B</span><span class="p">/</span><span class="nx">s</span><span class="cp">]</span>
<span class="nt">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="nt">374434792</span><span class="o">/</span><span class="nt">374434792</span> <span class="cp">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">07</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">47927932.74</span><span class="nx">B</span><span class="p">/</span><span class="nx">s</span><span class="cp">]</span>
<span class="o">/</span><span class="nt">usr</span><span class="o">/</span><span class="nt">local</span><span class="o">/</span><span class="nt">lib</span><span class="o">/</span><span class="nt">python3</span><span class="p">.</span><span class="nc">6</span><span class="o">/</span><span class="nt">dist-packages</span><span class="o">/</span><span class="nt">torch</span><span class="o">/</span><span class="nt">nn</span><span class="o">/</span><span class="nt">modules</span><span class="o">/</span><span class="nt">rnn</span><span class="p">.</span><span class="nc">py</span><span class="p">:</span><span class="nd">54</span><span class="o">:</span> <span class="nt">UserWarning</span><span class="o">:</span> <span class="nt">dropout</span> <span class="nt">option</span> <span class="nt">adds</span> <span class="nt">dropout</span> <span class="nt">after</span> <span class="nt">all</span> <span class="nt">but</span> <span class="nt">last</span> <span class="nt">recurrent</span> <span class="nt">layer</span><span class="o">,</span> <span class="nt">so</span> <span class="nt">non-zero</span> <span class="nt">dropout</span> <span class="nt">expects</span> <span class="nt">num_layers</span> <span class="nt">greater</span> <span class="nt">than</span> <span class="nt">1</span><span class="o">,</span> <span class="nt">but</span> <span class="nt">got</span> <span class="nt">dropout</span><span class="o">=</span><span class="nt">0</span><span class="p">.</span><span class="nc">5</span> <span class="nt">and</span> <span class="nt">num_layers</span><span class="o">=</span><span class="nt">1</span>
  <span class="s2">&quot;num_layers={}&quot;</span><span class="p">.</span><span class="nc">format</span><span class="o">(</span><span class="nt">dropout</span><span class="o">,</span> <span class="nt">num_layers</span><span class="o">))</span>


<span class="nt">Model</span> <span class="nt">has</span> <span class="nt">461114</span> <span class="nt">parameters</span>
<span class="nt">EPOCH</span> <span class="nt">1</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.5608,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.6483439079531595,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.48504498768062404,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.49849106627634976,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.5726962123308302,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.5608,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.5554788741148295</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.7942477876106194,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8454765420711672,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.7033276693176708,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.7144610587048233,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8102895316760798,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.7942477876106194,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.7887777126414355</span><span class="p">}</span>
<span class="nt">New</span> <span class="nt">best</span> <span class="nt">model</span> <span class="nt">0</span><span class="p">.</span><span class="nc">79</span>
<span class="nt">EPOCH</span> <span class="nt">2</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.806,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.799350329535837,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.7675872074813431,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.780728542640896,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8062829252605372,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.806,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8058397968891035</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8628318584070797,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8566120843164245,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.7974693543452065,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8182667932069821,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8675313347987196,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8628318584070797,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8625189847178025</span><span class="p">}</span>
<span class="nt">New</span> <span class="nt">best</span> <span class="nt">model</span> <span class="nt">0</span><span class="p">.</span><span class="nc">86</span>
<span class="nt">EPOCH</span> <span class="nt">3</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8678,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8675015318855253,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8346532456259291,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8484927361816553,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8682517001586247,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8678,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8677362764323896</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8451327433628318,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8284211573091326,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8093879960516328,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8110225138172149,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8691115810447773,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8451327433628318,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8465397357783465</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">4</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8872,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8764661421280517,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8546009991636673,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8643704500888516,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.887561002584866,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8872,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8872276932804481</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.911504424778761,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8515226408802844,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8617077224611437,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8561887828467433,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9122749445064818,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.911504424778761,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9118158975632823</span><span class="p">}</span>
<span class="nt">New</span> <span class="nt">best</span> <span class="nt">model</span> <span class="nt">0</span><span class="p">.</span><span class="nc">91</span>
<span class="nt">EPOCH</span> <span class="nt">5</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9034,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9068352283292169,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8843802250756597,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8946296708241798,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9040643245149811,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9034,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9035884797279896</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8871681415929203,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8310659320074388,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.841863153832931,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8355145420604436,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.8885588116644558,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8871681415929203,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8871217953267708</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">6</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9136,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9192746333288291,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8914669258673943,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.903828395837297,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9139512391702285,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9136,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.913614469191629</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9048672566371682,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8453363940567148,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8564313119872883,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8503405229048734,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.905338925288292,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9048672566371682,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9048873521303485</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">7</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9184,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9217954417236368,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9035341951741954,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9119837710405331,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9188094085046438,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9184,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9185065760698944</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9004424778761062,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8343728710441182,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8542340405568197,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8426629413676556,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9019737446759757,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9004424778761062,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9006848775343249</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">8</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9252,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9227662229391251,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9085845822017588,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9152560555320276,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9254505663098069,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9252,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9252609572329403</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.8960176991150443,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8848359324236518,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8515305594157283,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8641410893717477,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.897474904298379,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.8960176991150443,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.8954448264468791</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">9</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9366,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9421415595699045,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9253828413493465,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9332020129586184,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9367741614764589,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9366,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9366203849323997</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9004424778761062,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8408851907016573,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8542708251432938,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8466559111080202,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9022774132643538,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9004424778761062,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9006261595204735</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">10</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9422,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9415872377873563,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9301100255239593,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9356066415360083,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9423787344008276,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9422,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9422531801175381</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9026548672566371,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8534388800712419,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.855449985872144,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8538969412521858,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9037659180936365,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9026548672566371,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.90246529999771</span><span class="p">}</span>
<span class="nt">EPOCH</span> <span class="nt">11</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9432,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9422754608090832,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.938376139581592,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9402970803722553,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9432734858574917,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9432,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.943229377825017</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9137168141592921,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8628400105220431,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8646482805732667,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8633776502808389,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9132203845237589,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9137168141592921,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9130050592497775</span><span class="p">}</span>
<span class="nt">New</span> <span class="nt">best</span> <span class="nt">model</span> <span class="nt">0</span><span class="p">.</span><span class="nc">91</span>
<span class="nt">EPOCH</span> <span class="nt">12</span>
<span class="o">=================================</span>
<span class="nt">Training</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9544,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9557163129978826,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9458500359607124,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9506063779628039,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9545506681185594,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9544,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9544423559597639</span><span class="p">}</span>
<span class="nt">Validation</span> <span class="nt">Results</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.9092920353982301,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.8510768742634296,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.8608961905116529,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.8550990513587272,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9106944939486582,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.9092920353982301,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9093039549088799</span><span class="p">}</span>
<span class="nt">Final</span> <span class="nt">result</span>
<span class="p">{</span><span class="err">&#39;acc&#39;:</span> <span class="err">0.944,</span> <span class="err">&#39;mean_precision&#39;:</span> <span class="err">0.9333687372820768,</span> <span class="err">&#39;mean_recall&#39;:</span> <span class="err">0.9161547629123813,</span> <span class="err">&#39;macro_f1&#39;:</span> <span class="err">0.9230157805001022,</span> <span class="err">&#39;weighted_precision&#39;:</span> <span class="err">0.9449538854974426,</span> <span class="err">&#39;weighted_recall&#39;:</span> <span class="err">0.944,</span> <span class="err">&#39;weighted_f1&#39;:</span> <span class="err">0.9429751846143404</span><span class="p">}</span>





<span class="nt">0</span><span class="p">.</span><span class="nc">944</span>
</pre></div>


<p>Let's see how this number compares against a randomly initialized baseline model that is otherwise identical.  We dont really need to use such a huge embedding size in this case -- we are using word vectors instead of character compositional vectors and we dont really have enough information to train a huge word embedding from scratch.  Also, since we dont have much information, we will use lowercased features.  Note that using these word embeddings features, our model has <strong>6x more parameters than before</strong>.  Also, we might want to train it longer.</p>
<div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">Reader</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">VALID</span><span class="p">,</span> <span class="n">TEST</span><span class="p">,),</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">)</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">VALID</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TEST</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LSTMClassifier</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">rnn_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">])</span>

<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  &quot;num_layers={}&quot;.format(dropout, num_layers))


Model has 2801306 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.2542, &#39;mean_precision&#39;: 0.31261376969825, &#39;mean_recall&#39;: 0.2142077519956256, &#39;macro_f1&#39;: 0.21100023435767312, &#39;weighted_precision&#39;: 0.24503296037652494, &#39;weighted_recall&#39;: 0.2542, &#39;weighted_f1&#39;: 0.22759490197394544}
Validation Results
{&#39;acc&#39;: 0.31194690265486724, &#39;mean_precision&#39;: 0.30219607432329726, &#39;mean_recall&#39;: 0.2697651533307747, &#39;macro_f1&#39;: 0.23033350512330675, &#39;weighted_precision&#39;: 0.3308620779538906, &#39;weighted_recall&#39;: 0.31194690265486724, &#39;weighted_f1&#39;: 0.25984647084205925}
New best model 0.31
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.3776, &#39;mean_precision&#39;: 0.4211727454667504, &#39;mean_recall&#39;: 0.3614489295644783, &#39;macro_f1&#39;: 0.3731848509532312, &#39;weighted_precision&#39;: 0.37235350929169814, &#39;weighted_recall&#39;: 0.3776, &#39;weighted_f1&#39;: 0.3631077775707718}
Validation Results
{&#39;acc&#39;: 0.4557522123893805, &#39;mean_precision&#39;: 0.486368442230124, &#39;mean_recall&#39;: 0.44059437145396335, &#39;macro_f1&#39;: 0.4116212305386946, &#39;weighted_precision&#39;: 0.5028626993515615, &#39;weighted_recall&#39;: 0.4557522123893805, &#39;weighted_f1&#39;: 0.42325171491881114}
New best model 0.46
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.5432, &#39;mean_precision&#39;: 0.5874298893317987, &#39;mean_recall&#39;: 0.5213749406751867, &#39;macro_f1&#39;: 0.5432030532887705, &#39;weighted_precision&#39;: 0.5414128746603742, &#39;weighted_recall&#39;: 0.5432, &#39;weighted_f1&#39;: 0.539731134218227}
Validation Results
{&#39;acc&#39;: 0.6592920353982301, &#39;mean_precision&#39;: 0.6419746068058818, &#39;mean_recall&#39;: 0.6268845865056035, &#39;macro_f1&#39;: 0.6307977552497951, &#39;weighted_precision&#39;: 0.662392825769239, &#39;weighted_recall&#39;: 0.6592920353982301, &#39;weighted_f1&#39;: 0.6571270878109032}
New best model 0.66
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.6652, &#39;mean_precision&#39;: 0.7019592671173288, &#39;mean_recall&#39;: 0.6360073323821094, &#39;macro_f1&#39;: 0.6596012872763003, &#39;weighted_precision&#39;: 0.6699451752521243, &#39;weighted_recall&#39;: 0.6652, &#39;weighted_f1&#39;: 0.6663461696747198}
Validation Results
{&#39;acc&#39;: 0.7256637168141593, &#39;mean_precision&#39;: 0.6947344026048728, &#39;mean_recall&#39;: 0.684312146723145, &#39;macro_f1&#39;: 0.6882240153205471, &#39;weighted_precision&#39;: 0.7329104731535425, &#39;weighted_recall&#39;: 0.7256637168141593, &#39;weighted_f1&#39;: 0.7276818270316268}
New best model 0.73
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.7262, &#39;mean_precision&#39;: 0.7559759521433286, &#39;mean_recall&#39;: 0.6964030168119725, &#39;macro_f1&#39;: 0.718961419314074, &#39;weighted_precision&#39;: 0.7314068173369025, &#39;weighted_recall&#39;: 0.7262, &#39;weighted_f1&#39;: 0.7276772804705455}
Validation Results
{&#39;acc&#39;: 0.7699115044247787, &#39;mean_precision&#39;: 0.767162729738685, &#39;mean_recall&#39;: 0.7171683804327849, &#39;macro_f1&#39;: 0.7358018640759697, &#39;weighted_precision&#39;: 0.7869035814233268, &#39;weighted_recall&#39;: 0.7699115044247787, &#39;weighted_f1&#39;: 0.7730466432148493}
New best model 0.77
EPOCH 6
=================================
Training Results
{&#39;acc&#39;: 0.7774, &#39;mean_precision&#39;: 0.7991829240246574, &#39;mean_recall&#39;: 0.7460179937770648, &#39;macro_f1&#39;: 0.7670813561197591, &#39;weighted_precision&#39;: 0.7829082373273452, &#39;weighted_recall&#39;: 0.7774, &#39;weighted_f1&#39;: 0.7790066442175066}
Validation Results
{&#39;acc&#39;: 0.7942477876106194, &#39;mean_precision&#39;: 0.7722010233604815, &#39;mean_recall&#39;: 0.7413137565797516, &#39;macro_f1&#39;: 0.7527105440234411, &#39;weighted_precision&#39;: 0.7965885015875331, &#39;weighted_recall&#39;: 0.7942477876106194, &#39;weighted_f1&#39;: 0.7932362973950707}
New best model 0.79
EPOCH 7
=================================
Training Results
{&#39;acc&#39;: 0.8094, &#39;mean_precision&#39;: 0.8190739759778141, &#39;mean_recall&#39;: 0.7893403911783444, &#39;macro_f1&#39;: 0.802535501291079, &#39;weighted_precision&#39;: 0.8128192118492741, &#39;weighted_recall&#39;: 0.8094, &#39;weighted_f1&#39;: 0.8105827362652248}
Validation Results
{&#39;acc&#39;: 0.7876106194690266, &#39;mean_precision&#39;: 0.7485831299937852, &#39;mean_recall&#39;: 0.737125918471548, &#39;macro_f1&#39;: 0.739828985707053, &#39;weighted_precision&#39;: 0.7889226923611903, &#39;weighted_recall&#39;: 0.7876106194690266, &#39;weighted_f1&#39;: 0.7851833379237152}
EPOCH 8
=================================
Training Results
{&#39;acc&#39;: 0.8334, &#39;mean_precision&#39;: 0.8425566386344959, &#39;mean_recall&#39;: 0.8020487930554469, &#39;macro_f1&#39;: 0.8188927928986053, &#39;weighted_precision&#39;: 0.8361427439552401, &#39;weighted_recall&#39;: 0.8334, &#39;weighted_f1&#39;: 0.8341487335405394}
Validation Results
{&#39;acc&#39;: 0.8053097345132744, &#39;mean_precision&#39;: 0.7836886850840924, &#39;mean_recall&#39;: 0.7717037075656982, &#39;macro_f1&#39;: 0.7766933663665941, &#39;weighted_precision&#39;: 0.8124743795936054, &#39;weighted_recall&#39;: 0.8053097345132744, &#39;weighted_f1&#39;: 0.8076258267664438}
New best model 0.81
EPOCH 9
=================================
Training Results
{&#39;acc&#39;: 0.8468, &#39;mean_precision&#39;: 0.8504311729666333, &#39;mean_recall&#39;: 0.8200134573572487, &#39;macro_f1&#39;: 0.8331837029506359, &#39;weighted_precision&#39;: 0.8494250195065668, &#39;weighted_recall&#39;: 0.8468, &#39;weighted_f1&#39;: 0.8475914482379496}
Validation Results
{&#39;acc&#39;: 0.8163716814159292, &#39;mean_precision&#39;: 0.8122787276154813, &#39;mean_recall&#39;: 0.7728318623385028, &#39;macro_f1&#39;: 0.7845697172233551, &#39;weighted_precision&#39;: 0.841008158316879, &#39;weighted_recall&#39;: 0.8163716814159292, &#39;weighted_f1&#39;: 0.8194346806526578}
New best model 0.82
EPOCH 10
=================================
Training Results
{&#39;acc&#39;: 0.856, &#39;mean_precision&#39;: 0.8583456863001512, &#39;mean_recall&#39;: 0.8344367321617767, &#39;macro_f1&#39;: 0.8452794073478773, &#39;weighted_precision&#39;: 0.858502410730061, &#39;weighted_recall&#39;: 0.856, &#39;weighted_f1&#39;: 0.8568463379552975}
Validation Results
{&#39;acc&#39;: 0.827433628318584, &#39;mean_precision&#39;: 0.8065578820468894, &#39;mean_recall&#39;: 0.7875269000666668, &#39;macro_f1&#39;: 0.7948885464239536, &#39;weighted_precision&#39;: 0.8376851538502355, &#39;weighted_recall&#39;: 0.827433628318584, &#39;weighted_f1&#39;: 0.8300346063518604}
New best model 0.83
EPOCH 11
=================================
Training Results
{&#39;acc&#39;: 0.8752, &#39;mean_precision&#39;: 0.8867543443057883, &#39;mean_recall&#39;: 0.8682828032176982, &#39;macro_f1&#39;: 0.876877938560822, &#39;weighted_precision&#39;: 0.8765970442190595, &#39;weighted_recall&#39;: 0.8752, &#39;weighted_f1&#39;: 0.8756987373269298}
Validation Results
{&#39;acc&#39;: 0.8429203539823009, &#39;mean_precision&#39;: 0.810890350645565, &#39;mean_recall&#39;: 0.8200588537595558, &#39;macro_f1&#39;: 0.8091225485091558, &#39;weighted_precision&#39;: 0.856571882711008, &#39;weighted_recall&#39;: 0.8429203539823009, &#39;weighted_f1&#39;: 0.8457428127083414}
New best model 0.84
EPOCH 12
=================================
Training Results
{&#39;acc&#39;: 0.8792, &#39;mean_precision&#39;: 0.8792557729505756, &#39;mean_recall&#39;: 0.8559171118516193, &#39;macro_f1&#39;: 0.8664273096431591, &#39;weighted_precision&#39;: 0.8802943928708451, &#39;weighted_recall&#39;: 0.8792, &#39;weighted_f1&#39;: 0.8794929463166824}
Validation Results
{&#39;acc&#39;: 0.831858407079646, &#39;mean_precision&#39;: 0.7962677456184699, &#39;mean_recall&#39;: 0.8169955255150682, &#39;macro_f1&#39;: 0.8012212821990726, &#39;weighted_precision&#39;: 0.8439342848824284, &#39;weighted_recall&#39;: 0.831858407079646, &#39;weighted_f1&#39;: 0.8345906017116217}
EPOCH 13
=================================
Training Results
{&#39;acc&#39;: 0.8982, &#39;mean_precision&#39;: 0.8926979300525084, &#39;mean_recall&#39;: 0.8720075500179675, &#39;macro_f1&#39;: 0.8813865977662623, &#39;weighted_precision&#39;: 0.8990274368829654, &#39;weighted_recall&#39;: 0.8982, &#39;weighted_f1&#39;: 0.898400074877493}
Validation Results
{&#39;acc&#39;: 0.8407079646017699, &#39;mean_precision&#39;: 0.8044426437483548, &#39;mean_recall&#39;: 0.8230926174040855, &#39;macro_f1&#39;: 0.8115058510891844, &#39;weighted_precision&#39;: 0.8446897114706726, &#39;weighted_recall&#39;: 0.8407079646017699, &#39;weighted_f1&#39;: 0.8418088284238727}
EPOCH 14
=================================
Training Results
{&#39;acc&#39;: 0.8994, &#39;mean_precision&#39;: 0.90397473118525, &#39;mean_recall&#39;: 0.8869886283764901, &#39;macro_f1&#39;: 0.8949155550364044, &#39;weighted_precision&#39;: 0.9000862304408612, &#39;weighted_recall&#39;: 0.8994, &#39;weighted_f1&#39;: 0.8996270341701729}
Validation Results
{&#39;acc&#39;: 0.834070796460177, &#39;mean_precision&#39;: 0.7941534082526428, &#39;mean_recall&#39;: 0.8181802560779231, &#39;macro_f1&#39;: 0.802448595927142, &#39;weighted_precision&#39;: 0.839962405943381, &#39;weighted_recall&#39;: 0.834070796460177, &#39;weighted_f1&#39;: 0.8360121837053236}
EPOCH 15
=================================
Training Results
{&#39;acc&#39;: 0.9078, &#39;mean_precision&#39;: 0.9025906984450397, &#39;mean_recall&#39;: 0.8840592072689094, &#39;macro_f1&#39;: 0.8925740985975588, &#39;weighted_precision&#39;: 0.9079516195367331, &#39;weighted_recall&#39;: 0.9078, &#39;weighted_f1&#39;: 0.9077917625402113}
Validation Results
{&#39;acc&#39;: 0.8429203539823009, &#39;mean_precision&#39;: 0.8178604107482675, &#39;mean_recall&#39;: 0.8027279926613361, &#39;macro_f1&#39;: 0.807847400976306, &#39;weighted_precision&#39;: 0.8541454685154969, &#39;weighted_recall&#39;: 0.8429203539823009, &#39;weighted_f1&#39;: 0.8452297642709833}
EPOCH 16
=================================
Training Results
{&#39;acc&#39;: 0.9114, &#39;mean_precision&#39;: 0.9091156125381755, &#39;mean_recall&#39;: 0.8954153246439646, &#39;macro_f1&#39;: 0.901884018226399, &#39;weighted_precision&#39;: 0.9120534355149411, &#39;weighted_recall&#39;: 0.9114, &#39;weighted_f1&#39;: 0.9115938328769627}
Validation Results
{&#39;acc&#39;: 0.8584070796460177, &#39;mean_precision&#39;: 0.8452925879669096, &#39;mean_recall&#39;: 0.8140923455585375, &#39;macro_f1&#39;: 0.8271059195675882, &#39;weighted_precision&#39;: 0.866784367505974, &#39;weighted_recall&#39;: 0.8584070796460177, &#39;weighted_f1&#39;: 0.8601283537102449}
New best model 0.86
EPOCH 17
=================================
Training Results
{&#39;acc&#39;: 0.922, &#39;mean_precision&#39;: 0.92318827916946, &#39;mean_recall&#39;: 0.9167872228173993, &#39;macro_f1&#39;: 0.919907344495105, &#39;weighted_precision&#39;: 0.9222631334663767, &#39;weighted_recall&#39;: 0.922, &#39;weighted_f1&#39;: 0.9220983595773123}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8226381745596281, &#39;mean_recall&#39;: 0.8064587339697171, &#39;macro_f1&#39;: 0.8118331344786779, &#39;weighted_precision&#39;: 0.8588090104120005, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8509990153606489}
EPOCH 18
=================================
Training Results
{&#39;acc&#39;: 0.925, &#39;mean_precision&#39;: 0.9272713764228396, &#39;mean_recall&#39;: 0.9097196644145997, &#39;macro_f1&#39;: 0.9178903031944213, &#39;weighted_precision&#39;: 0.9256665310570704, &#39;weighted_recall&#39;: 0.925, &#39;weighted_f1&#39;: 0.9251760923127654}
Validation Results
{&#39;acc&#39;: 0.8362831858407079, &#39;mean_precision&#39;: 0.8130991700945112, &#39;mean_recall&#39;: 0.8186032795814143, &#39;macro_f1&#39;: 0.8123228744939271, &#39;weighted_precision&#39;: 0.8468684662820305, &#39;weighted_recall&#39;: 0.8362831858407079, &#39;weighted_f1&#39;: 0.8392648607279487}
EPOCH 19
=================================
Training Results
{&#39;acc&#39;: 0.9226, &#39;mean_precision&#39;: 0.9265697322783559, &#39;mean_recall&#39;: 0.907365970956147, &#39;macro_f1&#39;: 0.9162751616718158, &#39;weighted_precision&#39;: 0.9229974594112873, &#39;weighted_recall&#39;: 0.9226, &#39;weighted_f1&#39;: 0.922695479769021}
Validation Results
{&#39;acc&#39;: 0.8407079646017699, &#39;mean_precision&#39;: 0.7961368682179472, &#39;mean_recall&#39;: 0.8225977371214205, &#39;macro_f1&#39;: 0.8033500248964449, &#39;weighted_precision&#39;: 0.8499048273885906, &#39;weighted_recall&#39;: 0.8407079646017699, &#39;weighted_f1&#39;: 0.8433057108007154}
EPOCH 20
=================================
Training Results
{&#39;acc&#39;: 0.9306, &#39;mean_precision&#39;: 0.9325672078372992, &#39;mean_recall&#39;: 0.9292912885334105, &#39;macro_f1&#39;: 0.9308909230234336, &#39;weighted_precision&#39;: 0.9309373491584835, &#39;weighted_recall&#39;: 0.9306, &#39;weighted_f1&#39;: 0.9307301028725288}
Validation Results
{&#39;acc&#39;: 0.8451327433628318, &#39;mean_precision&#39;: 0.8169164169164169, &#39;mean_recall&#39;: 0.8240567649306224, &#39;macro_f1&#39;: 0.81237323931053, &#39;weighted_precision&#39;: 0.8649006598121644, &#39;weighted_recall&#39;: 0.8451327433628318, &#39;weighted_f1&#39;: 0.8481262461147536}
EPOCH 21
=================================
Training Results
{&#39;acc&#39;: 0.9372, &#39;mean_precision&#39;: 0.94778588624423, &#39;mean_recall&#39;: 0.931739382135247, &#39;macro_f1&#39;: 0.9392845360347503, &#39;weighted_precision&#39;: 0.9376509979046739, &#39;weighted_recall&#39;: 0.9372, &#39;weighted_f1&#39;: 0.9373365710922599}
Validation Results
{&#39;acc&#39;: 0.8429203539823009, &#39;mean_precision&#39;: 0.8122060187568131, &#39;mean_recall&#39;: 0.8039074327168304, &#39;macro_f1&#39;: 0.8074842893609094, &#39;weighted_precision&#39;: 0.846085726902366, &#39;weighted_recall&#39;: 0.8429203539823009, &#39;weighted_f1&#39;: 0.843907236330442}
EPOCH 22
=================================
Training Results
{&#39;acc&#39;: 0.9396, &#39;mean_precision&#39;: 0.9374128845763084, &#39;mean_recall&#39;: 0.919864102313256, &#39;macro_f1&#39;: 0.9279841844104714, &#39;weighted_precision&#39;: 0.9395460389520726, &#39;weighted_recall&#39;: 0.9396, &#39;weighted_f1&#39;: 0.9395077256432057}
Validation Results
{&#39;acc&#39;: 0.838495575221239, &#39;mean_precision&#39;: 0.8166287688346512, &#39;mean_recall&#39;: 0.7965319356459588, &#39;macro_f1&#39;: 0.8036210071046136, &#39;weighted_precision&#39;: 0.8514493271781142, &#39;weighted_recall&#39;: 0.838495575221239, &#39;weighted_f1&#39;: 0.8411121771904451}
EPOCH 23
=================================
Training Results
{&#39;acc&#39;: 0.9394, &#39;mean_precision&#39;: 0.9343864652716637, &#39;mean_recall&#39;: 0.9292029606780483, &#39;macro_f1&#39;: 0.9317217171943124, &#39;weighted_precision&#39;: 0.9395732746438947, &#39;weighted_recall&#39;: 0.9394, &#39;weighted_f1&#39;: 0.9394587072607552}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8152645128671007, &#39;mean_recall&#39;: 0.8101445689658334, &#39;macro_f1&#39;: 0.8116836837706645, &#39;weighted_precision&#39;: 0.853045900832462, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8499444374703017}
EPOCH 24
=================================
Training Results
{&#39;acc&#39;: 0.9366, &#39;mean_precision&#39;: 0.9385826391144599, &#39;mean_recall&#39;: 0.9310259128633419, &#39;macro_f1&#39;: 0.9346948428938683, &#39;weighted_precision&#39;: 0.9367440103332517, &#39;weighted_recall&#39;: 0.9366, &#39;weighted_f1&#39;: 0.9366526615949582}
Validation Results
{&#39;acc&#39;: 0.8473451327433629, &#39;mean_precision&#39;: 0.8025432410455261, &#39;mean_recall&#39;: 0.8283322432914666, &#39;macro_f1&#39;: 0.8061102573975748, &#39;weighted_precision&#39;: 0.861458116214064, &#39;weighted_recall&#39;: 0.8473451327433629, &#39;weighted_f1&#39;: 0.8502841373610759}
EPOCH 25
=================================
Training Results
{&#39;acc&#39;: 0.9474, &#39;mean_precision&#39;: 0.945203027270548, &#39;mean_recall&#39;: 0.9397940805142109, &#39;macro_f1&#39;: 0.9424193517790628, &#39;weighted_precision&#39;: 0.9476039831561757, &#39;weighted_recall&#39;: 0.9474, &#39;weighted_f1&#39;: 0.9474674977170525}
Validation Results
{&#39;acc&#39;: 0.8517699115044248, &#39;mean_precision&#39;: 0.8122309943824346, &#39;mean_recall&#39;: 0.8316675962171595, &#39;macro_f1&#39;: 0.817457525740406, &#39;weighted_precision&#39;: 0.8589009917207507, &#39;weighted_recall&#39;: 0.8517699115044248, &#39;weighted_f1&#39;: 0.8536305273856584}
EPOCH 26
=================================
Training Results
{&#39;acc&#39;: 0.9412, &#39;mean_precision&#39;: 0.9333724069841898, &#39;mean_recall&#39;: 0.9327119878566131, &#39;macro_f1&#39;: 0.9330083105008247, &#39;weighted_precision&#39;: 0.9415099002878724, &#39;weighted_recall&#39;: 0.9412, &#39;weighted_f1&#39;: 0.9413101950625798}
Validation Results
{&#39;acc&#39;: 0.8672566371681416, &#39;mean_precision&#39;: 0.8605083530628996, &#39;mean_recall&#39;: 0.8246033707390573, &#39;macro_f1&#39;: 0.8391902596303691, &#39;weighted_precision&#39;: 0.8669141290171042, &#39;weighted_recall&#39;: 0.8672566371681416, &#39;weighted_f1&#39;: 0.8665873995194234}
New best model 0.87
EPOCH 27
=================================
Training Results
{&#39;acc&#39;: 0.9452, &#39;mean_precision&#39;: 0.9393570838696085, &#39;mean_recall&#39;: 0.9381922191949007, &#39;macro_f1&#39;: 0.938758641015847, &#39;weighted_precision&#39;: 0.9451643947972791, &#39;weighted_recall&#39;: 0.9452, &#39;weighted_f1&#39;: 0.9451693027949712}
Validation Results
{&#39;acc&#39;: 0.8539823008849557, &#39;mean_precision&#39;: 0.8230172208866048, &#39;mean_recall&#39;: 0.8123173810979951, &#39;macro_f1&#39;: 0.8156989547159269, &#39;weighted_precision&#39;: 0.86038962724662, &#39;weighted_recall&#39;: 0.8539823008849557, &#39;weighted_f1&#39;: 0.8546422455744229}
EPOCH 28
=================================
Training Results
{&#39;acc&#39;: 0.9496, &#39;mean_precision&#39;: 0.9460303491056411, &#39;mean_recall&#39;: 0.9315008817259457, &#39;macro_f1&#39;: 0.938347207012888, &#39;weighted_precision&#39;: 0.9496092730822427, &#39;weighted_recall&#39;: 0.9496, &#39;weighted_f1&#39;: 0.9495572903768849}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8264021292481143, &#39;mean_recall&#39;: 0.8075150926865313, &#39;macro_f1&#39;: 0.8142132100384322, &#39;weighted_precision&#39;: 0.8614722274611524, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8519763491364317}
EPOCH 29
=================================
Training Results
{&#39;acc&#39;: 0.9492, &#39;mean_precision&#39;: 0.9523110976436452, &#39;mean_recall&#39;: 0.9431909498306, &#39;macro_f1&#39;: 0.9475782265270856, &#39;weighted_precision&#39;: 0.9492766331969764, &#39;weighted_recall&#39;: 0.9492, &#39;weighted_f1&#39;: 0.9492146339395731}
Validation Results
{&#39;acc&#39;: 0.8517699115044248, &#39;mean_precision&#39;: 0.8258343506751618, &#39;mean_recall&#39;: 0.8103395389633586, &#39;macro_f1&#39;: 0.8158066635203088, &#39;weighted_precision&#39;: 0.860982906249134, &#39;weighted_recall&#39;: 0.8517699115044248, &#39;weighted_f1&#39;: 0.8534222923294074}
EPOCH 30
=================================
Training Results
{&#39;acc&#39;: 0.9486, &#39;mean_precision&#39;: 0.9560017443521739, &#39;mean_recall&#39;: 0.9400692468871957, &#39;macro_f1&#39;: 0.9475746328501561, &#39;weighted_precision&#39;: 0.9488545438754485, &#39;weighted_recall&#39;: 0.9486, &#39;weighted_f1&#39;: 0.9486620015461529}
Validation Results
{&#39;acc&#39;: 0.8517699115044248, &#39;mean_precision&#39;: 0.8177916897275509, &#39;mean_recall&#39;: 0.8317336038356844, &#39;macro_f1&#39;: 0.8189379757266612, &#39;weighted_precision&#39;: 0.8641615919629556, &#39;weighted_recall&#39;: 0.8517699115044248, &#39;weighted_f1&#39;: 0.8543175095648456}
EPOCH 31
=================================
Training Results
{&#39;acc&#39;: 0.958, &#39;mean_precision&#39;: 0.9538284266182177, &#39;mean_recall&#39;: 0.9446486493014933, &#39;macro_f1&#39;: 0.9490660805682173, &#39;weighted_precision&#39;: 0.9581057645690427, &#39;weighted_recall&#39;: 0.958, &#39;weighted_f1&#39;: 0.958018653218701}
Validation Results
{&#39;acc&#39;: 0.8517699115044248, &#39;mean_precision&#39;: 0.8013986378685444, &#39;mean_recall&#39;: 0.8119935701678367, &#39;macro_f1&#39;: 0.804411328159357, &#39;weighted_precision&#39;: 0.8579675339835053, &#39;weighted_recall&#39;: 0.8517699115044248, &#39;weighted_f1&#39;: 0.8534679803361881}
EPOCH 32
=================================
Training Results
{&#39;acc&#39;: 0.954, &#39;mean_precision&#39;: 0.9512729471583152, &#39;mean_recall&#39;: 0.9522326430845925, &#39;macro_f1&#39;: 0.9517306869942752, &#39;weighted_precision&#39;: 0.9541486554643743, &#39;weighted_recall&#39;: 0.954, &#39;weighted_f1&#39;: 0.9540543038088639}
Validation Results
{&#39;acc&#39;: 0.8584070796460177, &#39;mean_precision&#39;: 0.8247875724959964, &#39;mean_recall&#39;: 0.813382140867244, &#39;macro_f1&#39;: 0.8148679951657951, &#39;weighted_precision&#39;: 0.8728418185739959, &#39;weighted_recall&#39;: 0.8584070796460177, &#39;weighted_f1&#39;: 0.8607256592741758}
EPOCH 33
=================================
Training Results
{&#39;acc&#39;: 0.957, &#39;mean_precision&#39;: 0.9565681480304719, &#39;mean_recall&#39;: 0.9454327046857133, &#39;macro_f1&#39;: 0.9507466808370677, &#39;weighted_precision&#39;: 0.9571322707135252, &#39;weighted_recall&#39;: 0.957, &#39;weighted_f1&#39;: 0.9570200735546852}
Validation Results
{&#39;acc&#39;: 0.8407079646017699, &#39;mean_precision&#39;: 0.8012295177369267, &#39;mean_recall&#39;: 0.7988123932835594, &#39;macro_f1&#39;: 0.7956541104094256, &#39;weighted_precision&#39;: 0.854940819905837, &#39;weighted_recall&#39;: 0.8407079646017699, &#39;weighted_f1&#39;: 0.843834784432942}
EPOCH 34
=================================
Training Results
{&#39;acc&#39;: 0.9562, &#39;mean_precision&#39;: 0.9492352170638396, &#39;mean_recall&#39;: 0.9501709445363726, &#39;macro_f1&#39;: 0.9496843838684074, &#39;weighted_precision&#39;: 0.9563024102937812, &#39;weighted_recall&#39;: 0.9562, &#39;weighted_f1&#39;: 0.9562374926155631}
Validation Results
{&#39;acc&#39;: 0.8539823008849557, &#39;mean_precision&#39;: 0.8074247463353991, &#39;mean_recall&#39;: 0.8132105098252905, &#39;macro_f1&#39;: 0.8095076634215594, &#39;weighted_precision&#39;: 0.8571530973672192, &#39;weighted_recall&#39;: 0.8539823008849557, &#39;weighted_f1&#39;: 0.8549969022822371}
EPOCH 35
=================================
Training Results
{&#39;acc&#39;: 0.958, &#39;mean_precision&#39;: 0.9581863087122168, &#39;mean_recall&#39;: 0.9556184908351323, &#39;macro_f1&#39;: 0.9568856509156166, &#39;weighted_precision&#39;: 0.9581083670874939, &#39;weighted_recall&#39;: 0.958, &#39;weighted_f1&#39;: 0.9580411865238977}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8178061479593234, &#39;mean_recall&#39;: 0.805632013633958, &#39;macro_f1&#39;: 0.807789691127139, &#39;weighted_precision&#39;: 0.8649796275543147, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8526672381640437}
EPOCH 36
=================================
Training Results
{&#39;acc&#39;: 0.9574, &#39;mean_precision&#39;: 0.9531272685674982, &#39;mean_recall&#39;: 0.9515769491207995, &#39;macro_f1&#39;: 0.9523405767311283, &#39;weighted_precision&#39;: 0.9573866537776834, &#39;weighted_recall&#39;: 0.9574, &#39;weighted_f1&#39;: 0.9573873211612607}
Validation Results
{&#39;acc&#39;: 0.8561946902654868, &#39;mean_precision&#39;: 0.8131151427942895, &#39;mean_recall&#39;: 0.8110658945033787, &#39;macro_f1&#39;: 0.8077795032214256, &#39;weighted_precision&#39;: 0.8693120626269972, &#39;weighted_recall&#39;: 0.8561946902654868, &#39;weighted_f1&#39;: 0.8589532280938094}
EPOCH 37
=================================
Training Results
{&#39;acc&#39;: 0.9566, &#39;mean_precision&#39;: 0.9589041860848261, &#39;mean_recall&#39;: 0.9547448481946009, &#39;macro_f1&#39;: 0.9567909158741493, &#39;weighted_precision&#39;: 0.9566010555107037, &#39;weighted_recall&#39;: 0.9566, &#39;weighted_f1&#39;: 0.9565890848568762}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8030750892649611, &#39;mean_recall&#39;: 0.8075017730562345, &#39;macro_f1&#39;: 0.8022990697875542, &#39;weighted_precision&#39;: 0.858293669895924, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.851768488915397}
EPOCH 38
=================================
Training Results
{&#39;acc&#39;: 0.957, &#39;mean_precision&#39;: 0.9544796723873579, &#39;mean_recall&#39;: 0.9522358611983669, &#39;macro_f1&#39;: 0.9533352482886838, &#39;weighted_precision&#39;: 0.9571066919837921, &#39;weighted_recall&#39;: 0.957, &#39;weighted_f1&#39;: 0.9570317579959188}
Validation Results
{&#39;acc&#39;: 0.8539823008849557, &#39;mean_precision&#39;: 0.8106297488632482, &#39;mean_recall&#39;: 0.8123418403963019, &#39;macro_f1&#39;: 0.8098548414705528, &#39;weighted_precision&#39;: 0.8585169985936104, &#39;weighted_recall&#39;: 0.8539823008849557, &#39;weighted_f1&#39;: 0.8548092957757126}
EPOCH 39
=================================
Training Results
{&#39;acc&#39;: 0.9564, &#39;mean_precision&#39;: 0.9532129259082603, &#39;mean_recall&#39;: 0.9506704508751782, &#39;macro_f1&#39;: 0.951926709753589, &#39;weighted_precision&#39;: 0.9564913201918928, &#39;weighted_recall&#39;: 0.9564, &#39;weighted_f1&#39;: 0.9564356136646421}
Validation Results
{&#39;acc&#39;: 0.8539823008849557, &#39;mean_precision&#39;: 0.8017848860212725, &#39;mean_recall&#39;: 0.8119553221526408, &#39;macro_f1&#39;: 0.804904791937732, &#39;weighted_precision&#39;: 0.8588867681742558, &#39;weighted_recall&#39;: 0.8539823008849557, &#39;weighted_f1&#39;: 0.855560943534421}
EPOCH 40
=================================
Training Results
{&#39;acc&#39;: 0.9644, &#39;mean_precision&#39;: 0.9670062774145092, &#39;mean_recall&#39;: 0.9573277463956331, &#39;macro_f1&#39;: 0.9619863456379548, &#39;weighted_precision&#39;: 0.9645118227152805, &#39;weighted_recall&#39;: 0.9644, &#39;weighted_f1&#39;: 0.9644225052829172}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8119564587793305, &#39;mean_recall&#39;: 0.8080099729691964, &#39;macro_f1&#39;: 0.8081568266024983, &#39;weighted_precision&#39;: 0.8580128676213757, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8519747328540073}
EPOCH 41
=================================
Training Results
{&#39;acc&#39;: 0.9628, &#39;mean_precision&#39;: 0.9582207266041486, &#39;mean_recall&#39;: 0.9557915435105366, &#39;macro_f1&#39;: 0.956989832500887, &#39;weighted_precision&#39;: 0.9628821971783511, &#39;weighted_recall&#39;: 0.9628, &#39;weighted_f1&#39;: 0.9628296736582989}
Validation Results
{&#39;acc&#39;: 0.8451327433628318, &#39;mean_precision&#39;: 0.7965093061348186, &#39;mean_recall&#39;: 0.8045728236987139, &#39;macro_f1&#39;: 0.7982598158685201, &#39;weighted_precision&#39;: 0.8513942451058316, &#39;weighted_recall&#39;: 0.8451327433628318, &#39;weighted_f1&#39;: 0.8470011392375405}
EPOCH 42
=================================
Training Results
{&#39;acc&#39;: 0.964, &#39;mean_precision&#39;: 0.9645740109204436, &#39;mean_recall&#39;: 0.9606825654964162, &#39;macro_f1&#39;: 0.9625915166364768, &#39;weighted_precision&#39;: 0.9640606955680181, &#39;weighted_recall&#39;: 0.964, &#39;weighted_f1&#39;: 0.9640155053392376}
Validation Results
{&#39;acc&#39;: 0.8495575221238938, &#39;mean_precision&#39;: 0.8037359987261851, &#39;mean_recall&#39;: 0.8058441622200901, &#39;macro_f1&#39;: 0.8012095203517711, &#39;weighted_precision&#39;: 0.8602910880270568, &#39;weighted_recall&#39;: 0.8495575221238938, &#39;weighted_f1&#39;: 0.8518937207419582}
EPOCH 43
=================================
Training Results
{&#39;acc&#39;: 0.967, &#39;mean_precision&#39;: 0.9673205256002168, &#39;mean_recall&#39;: 0.9608809490156882, &#39;macro_f1&#39;: 0.9640313629040639, &#39;weighted_precision&#39;: 0.967090742201184, &#39;weighted_recall&#39;: 0.967, &#39;weighted_f1&#39;: 0.9670273824588701}
Validation Results
{&#39;acc&#39;: 0.8584070796460177, &#39;mean_precision&#39;: 0.8071223611395778, &#39;mean_recall&#39;: 0.815180322836991, &#39;macro_f1&#39;: 0.8086659140417566, &#39;weighted_precision&#39;: 0.8654518199826157, &#39;weighted_recall&#39;: 0.8584070796460177, &#39;weighted_f1&#39;: 0.8603401318409323}
EPOCH 44
=================================
Training Results
{&#39;acc&#39;: 0.9658, &#39;mean_precision&#39;: 0.9609493483829002, &#39;mean_recall&#39;: 0.9637935616364777, &#39;macro_f1&#39;: 0.9623305485433838, &#39;weighted_precision&#39;: 0.9659282069261604, &#39;weighted_recall&#39;: 0.9658, &#39;weighted_f1&#39;: 0.9658413169266654}
Validation Results
{&#39;acc&#39;: 0.8451327433628318, &#39;mean_precision&#39;: 0.811964839602692, &#39;mean_recall&#39;: 0.804398454041185, &#39;macro_f1&#39;: 0.8075118081867685, &#39;weighted_precision&#39;: 0.8495195126057683, &#39;weighted_recall&#39;: 0.8451327433628318, &#39;weighted_f1&#39;: 0.846453823025803}
EPOCH 45
=================================
Training Results
{&#39;acc&#39;: 0.9658, &#39;mean_precision&#39;: 0.9598439053443757, &#39;mean_recall&#39;: 0.9526976401858064, &#39;macro_f1&#39;: 0.9561667547996912, &#39;weighted_precision&#39;: 0.9657984947117778, &#39;weighted_recall&#39;: 0.9658, &#39;weighted_f1&#39;: 0.9657855836823659}
Validation Results
{&#39;acc&#39;: 0.8539823008849557, &#39;mean_precision&#39;: 0.8027867894992161, &#39;mean_recall&#39;: 0.8119553221526408, &#39;macro_f1&#39;: 0.8053321278501304, &#39;weighted_precision&#39;: 0.8592071325485433, &#39;weighted_recall&#39;: 0.8539823008849557, &#39;weighted_f1&#39;: 0.8556693507865624}
EPOCH 46
=================================
Training Results
{&#39;acc&#39;: 0.9662, &#39;mean_precision&#39;: 0.9604700540065974, &#39;mean_recall&#39;: 0.9625075307979163, &#39;macro_f1&#39;: 0.9614812705685866, &#39;weighted_precision&#39;: 0.9662056816206401, &#39;weighted_recall&#39;: 0.9662, &#39;weighted_f1&#39;: 0.966200656893312}
Validation Results
{&#39;acc&#39;: 0.8606194690265486, &#39;mean_precision&#39;: 0.8296025254745819, &#39;mean_recall&#39;: 0.8174572008429252, &#39;macro_f1&#39;: 0.8224370751844012, &#39;weighted_precision&#39;: 0.8663240618203951, &#39;weighted_recall&#39;: 0.8606194690265486, &#39;weighted_f1&#39;: 0.8621524978508673}
EPOCH 47
=================================
Training Results
{&#39;acc&#39;: 0.9658, &#39;mean_precision&#39;: 0.9623643280997959, &#39;mean_recall&#39;: 0.9601608706065794, &#39;macro_f1&#39;: 0.9612521277633985, &#39;weighted_precision&#39;: 0.9657974850075743, &#39;weighted_recall&#39;: 0.9658, &#39;weighted_f1&#39;: 0.9657933462320052}
Validation Results
{&#39;acc&#39;: 0.8606194690265486, &#39;mean_precision&#39;: 0.8289130643629324, &#39;mean_recall&#39;: 0.8162020131702755, &#39;macro_f1&#39;: 0.8212697994296662, &#39;weighted_precision&#39;: 0.8663358703067995, &#39;weighted_recall&#39;: 0.8606194690265486, &#39;weighted_f1&#39;: 0.8619390343788721}
EPOCH 48
=================================
Training Results
{&#39;acc&#39;: 0.9694, &#39;mean_precision&#39;: 0.965498989334344, &#39;mean_recall&#39;: 0.9691871765140303, &#39;macro_f1&#39;: 0.9673126581580327, &#39;weighted_precision&#39;: 0.969441121137196, &#39;weighted_recall&#39;: 0.9694, &#39;weighted_f1&#39;: 0.969411138333605}
Validation Results
{&#39;acc&#39;: 0.8473451327433629, &#39;mean_precision&#39;: 0.8108888178689653, &#39;mean_recall&#39;: 0.8042876327132501, &#39;macro_f1&#39;: 0.8053138141785771, &#39;weighted_precision&#39;: 0.8569467358619901, &#39;weighted_recall&#39;: 0.8473451327433629, &#39;weighted_f1&#39;: 0.8498193213999172}
Final result
{&#39;acc&#39;: 0.882, &#39;mean_precision&#39;: 0.8966656639557661, &#39;mean_recall&#39;: 0.8599837937999005, &#39;macro_f1&#39;: 0.8737226125229776, &#39;weighted_precision&#39;: 0.8813809951547577, &#39;weighted_recall&#39;: 0.882, &#39;weighted_f1&#39;: 0.878768700658464}





0.882
</pre></div>


<h2>Conclusion</h2>
<p>Without even concatenating word features, our ELMo model, with far fewer parameters, surpasses the performance of the randomly initialized baseline, which we would expect.  It also significantly out-performs our CNN pre-trained, fine-tuned word embeddings baseline from the last section -- that model's max performance is around 93.  Note that this dataset is tiny, and the variance is large between datasets, but this model consistently outperforms both CNN and LSTM baselines.</p>
<p>Contextual embeddings consistently outperform non-contextual embeddings on almost every task in NLP, not just in text classification.  This method is becoming so commonly used that some papers have even started reporting this approach as a baseline.</p>
<h3>Some more references</h3>
<ul>
<li>
<p>The PyTorch examples actually contain a <a href="https://github.com/pytorch/examples/tree/master/word_language_model">nice word-language model</a></p>
</li>
<li>
<p>There is a <a href="https://www.tensorflow.org/tutorials/sequences/recurrent">Tensorflow tutorial</a> as well</p>
</li>
<li>
<p>The original source code for training <a href="https://github.com/allenai/bilm-tf/tree/master/bilm">ELMo's bilm is here</a></p>
</li>
<li>
<p><a href="https://github.com/dpressel/baseline/blob/master/python/baseline/pytorch/embeddings.py#L63">A succinct implementation</a> of character-compositional embeddings in Baseline for PyTorch</p>
</li>
</ul>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "leafyleap-2"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Mohcine Madkour &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>