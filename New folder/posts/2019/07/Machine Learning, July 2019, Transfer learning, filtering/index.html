<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mohcine Madkour, Big Data Architectures and more">


        <title>Transfer learning in NLP Part III: Fine-tuning a pre-trained model // Mohcine Madkour // Big Data Architectures and more</title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/mohcine-madkour.html" title="See posts by Mohcine Madkour">
                        <img class="avatar" alt="Mohcine Madkour" src="http://www.gravatar.com/avatar/ae08847efc1a85b710f326eb8ee2e907">
                </a>
                <h2 class="article-info">Mohcine Madkour</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>Sun 07 July 2019</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Transfer learning in NLP Part III: Fine-tuning a pre-trained model</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="../../../../tag/nlp/">NLP</a>
                                <a class="post-category" href="../../../../tag/july-2019/">July 2019</a>
                                <a class="post-category" href="../../../../tag/transfer-learning/">Transfer learning</a>
                                <a class="post-category" href="../../../../tag/filtering/">filtering</a>
                        </p>
                </header>
            </section>
            <p>In the last section, we looked at using a biLM networks layers as embeddings for our classification model.  In that approach, we maintain the exact same model architecture as before, but just switching our word embeddings out for context embeddings (or, more commonly, using them in concert).</p>
<p>The paper <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding
by Generative Pre-Training</a> (Radford et al 2018) explored a different approach, much more similar to what is typically done in computer vision.  In fine-tuning, we reuse the network architecture and simply replace the head.  We dont use any model specific architecture anymore, just a final layer.  There is an accompanying blog post <a href="https://openai.com/blog/language-unsupervised/">here</a>.  The image below is borrowed from that blog post</p>
<p><img alt="alt text" src="https://openai.com/content/images/2018/06/zero-shot-transfer@2x.png"></p>
<p>As we can see from the images, these models can rapidly improve our downstream performance with very limited fine-tuning supervision.</p>
<h2>The Transformer</h2>
<p>The original Transformer is an all-attention encoder-decoder model first introduced in <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need, Vaswani et al., 2017</a>.  It is described at a high-level in <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">this Google AI post</a>.
Here is an image of the model architecture for a Transformer:</p>
<p><img alt="Transformer Architecture" src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png"></p>
<p>The reference implementation from Google is the <a href="https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor">tensor2tensor repository</a>.  There is a lot going on in that codebase, which some people may find hard to follow.</p>
<p>We are going to go through each component in a hands-on manner, which will hopefully give you a visual feel of what is happening.</p>
<p>If you want to understand Transformers better, there is a terrific blog post called <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer, Rush, 2018</a> where you can see how to code up a Transformer from scratch to do Neural Machine Translation (NMT) while following along with the paper.</p>
<p>In versions used in practice, there are slight differences from the actual image, most notably, that layer norm is performed first.  Also, in a causal LM pre-training setting, as in the case of GPT, we have no need for the decoder, which simplifies our architecture substantially, leaving only a masked self-attention in the encoder (this prevents us from seeing the future as we predict).</p>
<h3>A Transformer Encoder Layer</h3>
<p>Here is code adapted from <a href="https://github.com/dpressel/baseline">Baseline</a> that implements a Transformer block used in a GPT-like architecture (pictured above).  We are going to take a closer look at these blocks, so lets think of this as the high-level overview.  The input to this class is a <code>torch.Tensor</code> of shape <code>BxT</code>.  The first sub-component in a Transformer block is the Multi-Headed Attention.  The second is the "FFN" shown in the image -- an MLP layer followed by a linear projection back to the original size.  We encapsulate these transformations in an <code>nn.Sequential</code>.  Notice that each sub-layer is also a residual connection.</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">pdrop</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">activation_type</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param num_heads (`int`): the number of heads for self-attention</span>
<span class="sd">        :param d_model (`int`): The model dimension size</span>
<span class="sd">        :param pdrop (`float`): The dropout probability</span>
<span class="sd">        :param scale (`bool`): Whether we are doing scaled dot-product attention</span>
<span class="sd">        :param activation_type: What activation type to use</span>
<span class="sd">        :param d_ff: The feed forward layer size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_ff</span> <span class="o">=</span> <span class="n">d_ff</span> <span class="k">if</span> <span class="n">d_ff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">pdrop</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_ff</span><span class="p">),</span>
                                 <span class="n">pytorch_activation</span><span class="p">(</span><span class="n">activation_type</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_ff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">pdrop</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: the inputs</span>
<span class="sd">        :param mask: a mask for the inputs</span>
<span class="sd">        :return: the encoder output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Builtin Attention mask</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>


<h3>Multi-headed Attention</h3>
<p>Multi-headed attention is one of the key innovations of the Transformer.  The idea was to allow each attention head to learn different relations.</p>
<p><img alt="MHA" src="https://1.bp.blogspot.com/-AVGK0ApREtk/WaiAuzddKVI/AAAAAAAAB_A/WPV5ropBU-cxrcMpqJBFHg73K9NX4vywwCLcBGAs/s1600/image2.png"></p>
<h4>Scaled dot product attention</h4>
<p>Here is a picture of the operations involved in scaled dot product attention.</p>
<p><img alt="MHA Architecture" src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png"></p>
<p><code>Q</code>, <code>K</code> and <code>V</code> are low-order projections of the input.  For Encoder-Decoders, the <code>Q</code> is a query vector in the decoder, and <code>K</code> and <code>V</code> are representations of the Encoder.  A dot product of the encoder keys and the query vector determines a set of weights that are applied against the <code>V</code> (again, also a representation of the encoder values).  In the case of the encoder, these are all drawn from the same input.  Basic dot product attention was actually introduced in <a href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation, Luong et al., 2014</a>, but in the the Transformer paper, the authors made a strong case that the basic dot product attention benefits from scaling.</p>
<p>This is implemented (again adapted from Baseline), as follows:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scaled dot product attention, as defined in https://arxiv.org/abs/1706.03762</span>

<span class="sd">    We apply the query to the keys to recieve our weights via softmax, which are then applied</span>
<span class="sd">    for each value, but in a series of efficient matrix operations.  In the case of self-attention,</span>
<span class="sd">    the key, query and values are all low order projections of the same input.</span>

<span class="sd">    :param query: a query for alignment. Can come from self in case of self-attn or decoder in case of E/D</span>
<span class="sd">    :param key: a set of keys from encoder or self</span>
<span class="sd">    :param value: a set of values from encoder or self</span>
<span class="sd">    :param mask: masking (for destination) to prevent seeing what we shouldnt</span>
<span class="sd">    :param dropout: apply dropout operator post-attention (this is not a float)</span>
<span class="sd">    :return: A tensor that is (BxHxTxT)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># (., H, T, T) = (., H, T, D) x (., H, D, T)</span>
    <span class="n">d_k</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">weights</span>
</pre></div>


<h4>The Multi-head part</h4>
<p>Each of the attention operations above that we apply is going to learn some weighted representation of our input -- what are we paying attention to?  There are lots of things that might be useful!   We might want to attend to the next word for language modeling.  To remember what we said, we might want to learn something like which pronouns refer to which nouns that we saw in previous tokens (this is called anaphora resolution and is a subset of coreference resolution).  We might hope that it picks up parse dependencies, that could help us with tasks that benefit from syntax.  Remember that each of our <code>Q</code>, <code>K</code> and <code>V</code> are low-order projections of our input.  What if we had many low-order projections and used each to learn different weightings?  This  is exactly what multi-head attention is.  Each "head" does the operation above and learns something meaningful (or at least, we hope it does!).</p>
<p>Here is some code that implements multi-headed attention using our function above:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadedAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-headed attention from https://arxiv.org/abs/1706.03762 via http://nlp.seas.harvard.edu/2018/04/03/attention.html</span>

<span class="sd">    Multi-headed attention provides multiple looks of low-order projections K, Q and V using an attention function</span>
<span class="sd">    (specifically `scaled_dot_product_attention` in the paper.  This allows multiple relationships to be illuminated</span>
<span class="sd">    via attention on different positional and representational information from each head.</span>

<span class="sd">    The number of heads `h` times the low-order projection dim `d_k` is equal to `d_model` (which is asserted upfront).</span>
<span class="sd">    This means that each weight matrix can be simply represented as a linear transformation from `d_model` to `d_model`,</span>
<span class="sd">    and partitioned into heads after the fact.</span>

<span class="sd">    Finally, an output projection is applied which brings the output space back to `d_model`, in preparation for the</span>
<span class="sd">    sub-sequent `FFN` sub-layer.</span>

<span class="sd">    There are 3 uses of multi-head attention in the Transformer.</span>
<span class="sd">    For encoder-decoder layers, the queries come from the previous decoder layer, and the memory keys come from</span>
<span class="sd">    the encoder.  For encoder layers, the K, Q and V all come from the output of the previous layer of the encoder.</span>
<span class="sd">    And for self-attention in the decoder, K, Q and V all come from the decoder, but here it is masked to prevent using</span>
<span class="sd">    future values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor for multi-headed attention</span>

<span class="sd">        :param h: The number of heads</span>
<span class="sd">        :param d_model: The model hidden size</span>
<span class="sd">        :param dropout (``float``): The amount of dropout to use</span>
<span class="sd">        :param attn_fn: A function to apply attention, defaults to SDP</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadedAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">h</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_Q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_K</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_V</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_O</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_fn</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span> <span class="k">if</span> <span class="n">scale</span> <span class="k">else</span> <span class="n">dot_product_attention</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Low-order projections of query, key and value into multiple heads, then attention application and dropout</span>

<span class="sd">        :param query: a query for alignment. Can come from self in case of self-attn or decoder in case of E/D</span>
<span class="sd">        :param key: a set of keys from encoder or self</span>
<span class="sd">        :param value: a set of values from encoder or self</span>
<span class="sd">        :param mask: masking (for destination) to prevent seeing what we shouldnt</span>
<span class="sd">        :return: Multi-head attention output, result of attention application to sequence (B, T, d_model)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batchsz</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># (B, H, T, D)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_Q</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batchsz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_K</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batchsz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_V</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batchsz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_fn</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> \
            <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batchsz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_O</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>


<p>We are going to take a look at how multi-headed attention works visually. To do this, we are going to use the <a href="https://github.com/jessevig/bertviz">viz-bert codebase</a> from Jesse Vig.  The accompanying paper is <a href="https://arxiv.org/pdf/1906.05714.pdf">A Multiscale Visualization of Attention in the Transformer Model, Vig, 2019</a>.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="err">!</span><span class="n">test</span> <span class="o">-</span><span class="n">d</span> <span class="n">bertviz_repo</span> <span class="o">&amp;&amp;</span> <span class="n">echo</span> <span class="s2">&quot;FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo&quot;</span>
<span class="c1"># !rm -r bertviz_repo # Uncomment if you need a clean pull from repo</span>
<span class="err">!</span><span class="n">test</span> <span class="o">-</span><span class="n">d</span> <span class="n">bertviz_repo</span> <span class="o">||</span> <span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">jessevig</span><span class="o">/</span><span class="n">bertviz</span> <span class="n">bertviz_repo</span>
<span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;bertviz_repo&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
  <span class="n">sys</span><span class="o">.</span><span class="n">path</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;bertviz_repo&#39;</span><span class="p">]</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">regex</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Cloning</span> <span class="n">into</span> <span class="err">&#39;</span><span class="n">bertviz_repo</span><span class="err">&#39;</span><span class="p">...</span>
<span class="nl">remote</span><span class="p">:</span> <span class="n">Enumerating</span> <span class="nl">objects</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">done</span><span class="p">.</span><span class="err"></span><span class="p">[</span><span class="n">K</span>
<span class="nl">remote</span><span class="p">:</span> <span class="n">Counting</span> <span class="nl">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span><span class="p">),</span> <span class="n">done</span><span class="p">.</span><span class="err"></span><span class="p">[</span><span class="n">K</span>
<span class="nl">remote</span><span class="p">:</span> <span class="n">Compressing</span> <span class="nl">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span><span class="p">),</span> <span class="n">done</span><span class="p">.</span><span class="err"></span><span class="p">[</span><span class="n">K</span>
<span class="nl">remote</span><span class="p">:</span> <span class="n">Total</span> <span class="mi">488</span> <span class="p">(</span><span class="n">delta</span> <span class="mi">0</span><span class="p">),</span> <span class="n">reused</span> <span class="mi">1</span> <span class="p">(</span><span class="n">delta</span> <span class="mi">0</span><span class="p">),</span> <span class="n">pack</span><span class="o">-</span><span class="n">reused</span> <span class="mi">485</span><span class="err"></span><span class="p">[</span><span class="n">K</span>
<span class="n">Receiving</span> <span class="nl">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">488</span><span class="o">/</span><span class="mi">488</span><span class="p">),</span> <span class="mf">37.01</span> <span class="n">MiB</span> <span class="o">|</span> <span class="mf">22.80</span> <span class="n">MiB</span><span class="o">/</span><span class="n">s</span><span class="p">,</span> <span class="n">done</span><span class="p">.</span>
<span class="n">Resolving</span> <span class="nl">deltas</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">294</span><span class="o">/</span><span class="mi">294</span><span class="p">),</span> <span class="n">done</span><span class="p">.</span>
<span class="n">Collecting</span> <span class="n">regex</span>
<span class="err"></span><span class="p">[</span><span class="o">?</span><span class="mi">25l</span>  <span class="n">Downloading</span> <span class="nl">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)</span>
<span class="err"></span><span class="p">[</span><span class="n">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">655</span><span class="n">kB</span> <span class="mf">9.8</span><span class="n">MB</span><span class="o">/</span><span class="n">s</span> 
<span class="err"></span><span class="p">[</span><span class="o">?</span><span class="mi">25</span><span class="n">hBuilding</span> <span class="n">wheels</span> <span class="k">for</span> <span class="n">collected</span> <span class="nl">packages</span><span class="p">:</span> <span class="n">regex</span>
  <span class="n">Building</span> <span class="n">wheel</span> <span class="k">for</span> <span class="n">regex</span> <span class="p">(</span><span class="n">setup</span><span class="p">.</span><span class="n">py</span><span class="p">)</span> <span class="p">...</span> <span class="err"></span><span class="p">[</span><span class="o">?</span><span class="mi">25l</span><span class="err"></span><span class="p">[</span><span class="o">?</span><span class="mi">25</span><span class="n">hdone</span>
  <span class="n">Stored</span> <span class="k">in</span> <span class="nl">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">cache</span><span class="o">/</span><span class="n">pip</span><span class="o">/</span><span class="n">wheels</span><span class="o">/</span><span class="mi">35</span><span class="o">/</span><span class="n">e4</span><span class="o">/</span><span class="mi">80</span><span class="o">/</span><span class="n">abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473</span>
<span class="n">Successfully</span> <span class="n">built</span> <span class="n">regex</span>
<span class="n">Installing</span> <span class="n">collected</span> <span class="nl">packages</span><span class="p">:</span> <span class="n">regex</span>
<span class="n">Successfully</span> <span class="n">installed</span> <span class="n">regex</span><span class="o">-</span><span class="mf">2019.6.8</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bertviz</span> <span class="kn">import</span> <span class="n">attention</span><span class="p">,</span> <span class="n">visualization</span>
<span class="kn">from</span> <span class="nn">bertviz.pytorch_pretrained_bert</span> <span class="kn">import</span> <span class="n">BertModel</span> <span class="k">as</span> <span class="n">VizBertModel</span>
<span class="kn">from</span> <span class="nn">bertviz.pytorch_pretrained_bert</span> <span class="kn">import</span> <span class="n">BertTokenizer</span> <span class="k">as</span> <span class="n">VizBertTokenizer</span>
</pre></div>


<div class="highlight"><pre><span></span>Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
</pre></div>


<div class="highlight"><pre><span></span><span class="o">%%</span><span class="nx">javascript</span>
<span class="nx">require</span><span class="p">.</span><span class="nx">config</span><span class="p">({</span>
  <span class="nx">paths</span><span class="o">:</span> <span class="p">{</span>
      <span class="nx">d3</span><span class="o">:</span> <span class="s1">&#39;//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min&#39;</span>
  <span class="p">}</span>
<span class="p">});</span>
</pre></div>


<div class="highlight"><pre><span></span>&amp;lt;IPython.core.display.Javascript object&amp;gt;
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">call_html</span><span class="p">():</span>
  <span class="kn">import</span> <span class="nn">IPython</span>
  <span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">        &lt;script src=&quot;/static/components/requirejs/require.js&quot;&gt;&lt;/script&gt;</span>
<span class="s1">        &lt;script&gt;</span>
<span class="s1">          requirejs.config({</span>
<span class="s1">            paths: {</span>
<span class="s1">              base: &#39;/static/base&#39;,</span>
<span class="s1">              &quot;d3&quot;: &quot;https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min&quot;,</span>
<span class="s1">              jquery: &#39;//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min&#39;,</span>
<span class="s1">            },</span>
<span class="s1">          });</span>
<span class="s1">        &lt;/script&gt;</span>
<span class="s1">        &#39;&#39;&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">VizBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">VizBertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<span class="n">sentence_a</span> <span class="o">=</span> <span class="s2">&quot;The dog crossed the road .&quot;</span>
<span class="n">sentence_b</span> <span class="o">=</span> <span class="s2">&quot;The owner came out and put him on a leash .&quot;</span>
<span class="n">attention_visualizer</span> <span class="o">=</span> <span class="n">visualization</span><span class="o">.</span><span class="n">AttentionVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">attention_visualizer</span><span class="o">.</span><span class="n">get_viz_data</span><span class="p">(</span><span class="n">sentence_a</span><span class="p">,</span> <span class="n">sentence_b</span><span class="p">)</span>
<span class="n">call_html</span><span class="p">()</span>
<span class="n">attention</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="p">,</span> <span class="n">attn</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="nt">407873900</span><span class="o">/</span><span class="nt">407873900</span> <span class="cp">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">14</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">27887659.37</span><span class="nx">B</span><span class="p">/</span><span class="nx">s</span><span class="cp">]</span>
<span class="nt">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="nt">231508</span><span class="o">/</span><span class="nt">231508</span> <span class="cp">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">913649.61</span><span class="nx">B</span><span class="p">/</span><span class="nx">s</span><span class="cp">]</span>




    <span class="o">&amp;</span><span class="nt">lt</span><span class="o">;</span><span class="nt">script</span> <span class="nt">src</span><span class="o">=</span><span class="s2">&quot;/static/components/requirejs/require.js&quot;</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;&amp;</span><span class="nt">lt</span><span class="o">;/</span><span class="nt">script</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;</span>
    <span class="o">&amp;</span><span class="nt">lt</span><span class="o">;</span><span class="nt">script</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;</span>
      <span class="nt">requirejs</span><span class="p">.</span><span class="nc">config</span><span class="o">(</span><span class="p">{</span>
        <span class="n">paths</span><span class="p">:</span> <span class="err">{</span>
          <span class="n">base</span><span class="o">:</span> <span class="s1">&#39;/static/base&#39;</span><span class="p">,</span>
          <span class="s2">&quot;d3&quot;</span><span class="o">:</span> <span class="s2">&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min&quot;</span><span class="p">,</span>
          <span class="n">jquery</span><span class="o">:</span> <span class="s1">&#39;//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min&#39;</span><span class="p">,</span>
        <span class="p">}</span><span class="o">,</span>
      <span class="err">}</span><span class="o">);</span>
    <span class="o">&amp;</span><span class="nt">lt</span><span class="o">;/</span><span class="nt">script</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;</span>
</pre></div>


<p><span style="user-select:none">
    Layer: <select id="layer"></select>
    Attention: <select id="att_type">
      <option value="all">All</option>
      <option value="a">Sentence A self-attention</option>
      <option value="b">Sentence B self-attention</option>
      <option value="ab">Sentence A -&gt; Sentence B</option>
      <option value="ba">Sentence B -&gt; Sentence A</option>
    </select>
  </span>
  <div id='vis'></div></p>
<div class="highlight"><pre><span></span>&amp;lt;IPython.core.display.Javascript object&amp;gt;



&amp;lt;IPython.core.display.Javascript object&amp;gt;
</pre></div>


<p>Try playing around with <code>sentence_a</code> and <code>sentence_b</code>.  You can select and unselect different attention heads, as well as the layer that you are visualizing.  There is a lot going on here.  <a href="https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77">This blog post</a>  by Jesse Vig, the author of the software we are using to render the attention heads above, discusses how BERT attention heads learn various types of attention.  <a href="https://arxiv.org/abs/1906.04341">Clark et al 2019 have a paper</a> that also delves into what learns, particular in the context of our linguistic notions of syntax</p>
<p>It turns out BERT learns a lot of stuff:</p>
<ul>
<li>
<p><strong>next/previous/identical word tracking</strong></p>
</li>
<li>
<p><strong>stuff that correlates closely to linguistic notions of syntax</strong>:  </p>
</li>
<li>
<p>BERT attention heads learn something like coreference</p>
</li>
<li>BERT attention heads learn some approximation of dependency parsing.  Different attention heads learn different dependency/governor relationships</li>
</ul>
<h4>Multi-Headed Attention is easy now in PyTorch!!</h4>
<p>This operation is now built into PyTorch.  There is a caveat that only scaled-dot product attention is supported.  The code above does not use that module since it supports both scaled and unscaled attention.</p>
<h3>Positional embeddings</h3>
<p>To eliminate auto-regressive (RNN) models from the transformer, positional embeddings need to be created and added to the word embeddings.  Otherwise, during attention there would be no way to account for word position. There are several ways to support positional embeddings.</p>
<p>The first way is very simple -- you just need to create a <code>nn.Embedding</code> that you give your offsets for each token.  Embedding representations will be learned for each position, but you can only learn up to the number of positions you have seen.</p>
<p>Another way, used in the original Transformer is to embed a bunch of sinusoids with different frequencies that are a function of the position:</p>
<p>$$PE_{(pos,2i)}=sin(pos/10000^{2i}/dmodel)$$
$$PE_{(pos,2i+1)}=cos(pos/10000^{2i}/dmodel)$$ </p>
<p>where $pos$ is the position and $i$ is the dimension corresponding to a sinusoid. The wavelengths form a geometric progression from $2\pi$ to $10000\times2\pi$.</p>
<h2>BERT</h2>
<p>For this section of the tutorial, we are going to fine-tune BERT <a href="https://arxiv.org/abs/1810.04805">Devlin et al 2018</a>, a transformer architecture that replaces the causal LM objective with 2 new objectives:</p>
<ol>
<li><strong>Masking out words</strong> with some probability, predict the missing words (MLM objective)</li>
</ol>
<p><img alt="MLM" src="https://2.bp.blogspot.com/-pNxcHHXNZg0/W9iv3evVyOI/AAAAAAAADfA/KTSvKXNzzL0W8ry28PPl7nYI1CG_5WuvwCLcBGAs/s1600/f1.png"></p>
<ol>
<li>Given 2 adjacent sentences, <strong>predict if the second sentence follows the first</strong> (NSP objective)</li>
</ol>
<p><img alt="NSP" src="https://4.bp.blogspot.com/-K_7yu3kjF18/W9iv-R-MnyI/AAAAAAAADfE/xUwR_G1iTY0vq9X-Z3LnW5t4NLS9BQzdgCLcBGAs/s1600/f2.png"></p>
<p>From an architecture diagram, <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">this blog post announcing BERT</a> notes the differences:</p>
<p><img alt="BERT vs GPT and ELMo" src="https://1.bp.blogspot.com/-RLAbr6kPNUo/W9is5FwUXmI/AAAAAAAADeU/5y9466Zoyoc96vqLjbruLK8i_t8qEdHnQCLcBGAs/s1600/image3.png"></p>
<p>Our model will simply build on the existing model architecture with a single transformation layer to the output number of classes.  BERT is <a href="https://github.com/google-research/bert">open source</a> but the code is in TensorFlow, and since this tutorial is written in PyTorch, we need a different solution.  We will use the <a href="https://github.com/huggingface/pytorch-pretrained-BERT">Hugging Face Transformer codebase</a> as our API -- it can read in the original Google-trained weights.</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">pretrained</span><span class="o">-</span><span class="n">bert</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">Collecting</span> <span class="nt">pytorch-pretrained-bert</span>
<span class="err"></span><span class="cp">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">l</span>  <span class="nx">Downloading</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)</span>
<span class="err">[</span><span class="nx">K</span>     <span class="o">|</span><span class="err">████████████████████████████████</span><span class="o">|</span> <span class="mi">133</span><span class="nx">kB</span> <span class="mf">9.5</span><span class="nx">MB</span><span class="p">/</span><span class="nx">s</span> 
<span class="err">[</span><span class="o">?</span><span class="mi">25</span><span class="nx">hRequirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">regex</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">2019.6.8</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">torch</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.4.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.1.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">numpy</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.16.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">boto3</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.9.175</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">requests</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.21.0</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="n">tqdm</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">4.28.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">botocore</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.13.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.12.175</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.12.175</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">jmespath</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.0.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.7.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.9.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">s3transfer</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">0.3.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.2.0</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.2.1</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">idna</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">2.9</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.8</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">chardet</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">3.1.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">3.0.2</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">3.0.4</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">certifi</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2017.4.17</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">2019.6.16</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">urllib3</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.25</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.21.1</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">requests</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.24.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">docutils</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">0.10</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">botocore</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.13.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.12.175</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">0.14</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">python</span><span class="na">-dateutil</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">3.0.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.1</span><span class="p">;</span> <span class="nx">python_version</span> <span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span> <span class="s2">&quot;2.7&quot;</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">botocore</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.13.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.12.175</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">2.5.3</span><span class="p">)</span>
<span class="nx">Requirement</span> <span class="nx">already</span> <span class="nx">satisfied</span><span class="p">:</span> <span class="nx">six</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.5</span> <span class="k">in</span> <span class="p">/</span><span class="nx">usr</span><span class="p">/</span><span class="nb">local</span><span class="p">/</span><span class="nx">lib</span><span class="p">/</span><span class="nx">python3.6</span><span class="p">/</span><span class="nx">dist</span><span class="na">-packages</span> <span class="p">(</span><span class="nx">from</span> <span class="nx">python</span><span class="na">-dateutil</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">3.0.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">2.1</span><span class="p">;</span> <span class="nx">python_version</span> <span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span> <span class="s2">&quot;2.7&quot;</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">botocore</span><span class="o">&amp;</span><span class="nx nx-Member">lt</span><span class="p">;</span><span class="mf">1.13.0</span><span class="p">,</span><span class="o">&amp;</span><span class="nx nx-Member">gt</span><span class="p">;</span><span class="o">=</span><span class="mf">1.12.175</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">boto3</span><span class="o">-&amp;</span><span class="nb">gt</span><span class="p">;</span><span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="p">)</span> <span class="p">(</span><span class="mf">1.12.0</span><span class="p">)</span>
<span class="nx">Installing</span> <span class="nx">collected</span> <span class="nx">packages</span><span class="p">:</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span>
<span class="nx">Successfully</span> <span class="nx">installed</span> <span class="nx">pytorch</span><span class="na">-pretrained-bert</span><span class="o">-</span><span class="mf">0.6.2</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_bert.tokenization</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_bert.modeling</span> <span class="kn">import</span> <span class="n">BertModel</span>
</pre></div>


<h3>Tokenization in BERT</h3>
<p>In the last sequence, we talked about how ELMo biLMs can limit their parameters while accounting for unseen words using character-compositional word embeddings.  This technique is very powerful, but its also slow.  It is common in NMT to use some sort of sub-word encoding that limits the vocabulary size, but allows us to not have unattested words.  The <code>tensor2tensor</code> codebase, for example, creates an invertible encoding for words into sub-tokens with a limited vocabulary.  The tokenizer is built from a corpus upfront and stored in a file, and then can be used to encode text.</p>
<p>There are 4 phases in this algorithm described in the tensor2tensor codebase:</p>
<div class="highlight"><pre><span></span>1. Tokenize into a list of tokens.  Each token is a unicode string of either
  all alphanumeric characters or all non-alphanumeric characters.  We drop
  tokens consisting of a single space that are between two alphanumeric
  tokens.
2. Escape each token.  This escapes away special and out-of-vocabulary
  characters, and makes sure that each token ends with an underscore, and
  has no other underscores.
3. Represent each escaped token as a the concatenation of a list of subtokens
  from the limited vocabulary.  Subtoken selection is done greedily from
  beginning to end.  That is, we construct the list in order, always picking
  the longest subtoken in our vocabulary that matches a prefix of the
  remaining portion of the encoded token.
4. Concatenate these lists.  This concatenation is invertible due to the
  fact that the trailing underscores indicate when one list is finished.
</pre></div>


<p>We can access Google's trained BERT Tokenizer via the Hugging Face API</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">whitespace_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 

<span class="k">def</span> <span class="nf">sst2_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="n">REPLACE</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;&#39;s&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;s &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ve&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ve &quot;</span><span class="p">,</span>
                <span class="s2">&quot;n&#39;t&quot;</span><span class="p">:</span> <span class="s2">&quot; n&#39;t &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;re&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;re &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;d&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;d &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ll&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ll &quot;</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="p">:</span> <span class="s2">&quot; , &quot;</span><span class="p">,</span>
                <span class="s2">&quot;!&quot;</span><span class="p">:</span> <span class="s2">&quot; ! &quot;</span><span class="p">,</span>
                <span class="p">}</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^A-Za-z0-9(),!?\&#39;\`]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">REPLACE</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

<span class="n">BERT_TOKENIZER</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<span class="n">BERT_MODEL</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">bert_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">pretokenizer</span><span class="o">=</span><span class="n">whitespace_tokenizer</span><span class="p">):</span>
    <span class="n">subwords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;[CLS]&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">pretokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">:</span>
            <span class="n">subword</span> <span class="o">=</span> <span class="s1">&#39;[UNK]&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">subword</span> <span class="o">=</span> <span class="n">BERT_TOKENIZER</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">subwords</span> <span class="o">+=</span> <span class="n">subword</span>
    <span class="k">return</span> <span class="n">subwords</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;[SEP]&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">bert_vectorizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">BERT_TOKENIZER</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1">#return [BERT_TOKENIZER.vocab.get(subword, BERT_TOKENIZER.vocab[&#39;[PAD]&#39;]) for subword in sentence]</span>
</pre></div>


<p>Our model this time around is very simple.  It has an output linear layer that comes from pooled output from BERT</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FineTuneClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="p">[]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
        <span class="n">input_units</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="n">output_units</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
            <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_units</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
            <span class="n">input_units</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">output_units</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">sequence</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">x</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">input_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">pooled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">input_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">)</span>

        <span class="n">stacked</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">stacked</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p>All the rest of our code comes from the previous sections</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="k">class</span> <span class="nc">ConfusionMatrix</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Confusion matrix with metrics</span>

<span class="sd">    This class accumulates classification output, and tracks it in a confusion matrix.</span>
<span class="sd">    Metrics are available that use the confusion matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor with input labels</span>

<span class="sd">        :param labels: Either a dictionary (`k=int,v=str`) or an array of labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">nc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nc</span><span class="p">,</span> <span class="n">nc</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a single value to the confusion matrix based off `truth` and `guess`</span>

<span class="sd">        :param truth: The real `y` value (or ground truth label)</span>
<span class="sd">        :param guess: The guess for `y` value (or assertion)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:&gt;{width}}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)):</span>
                <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;{:{width}d}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfile</span><span class="p">):</span>
        <span class="n">ordered_fieldnames</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="n">l</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">])</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">outfile</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">dw</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">ordered_fieldnames</span><span class="p">)</span>
            <span class="n">dw</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">):</span>
                <span class="n">row_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
                <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]})</span>
                <span class="n">dw</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span> <span class="o">*=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_correct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the diagonals of the confusion matrix</span>

<span class="sd">        :return: (``int``) Number of correct classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_total</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get total classifications</span>

<span class="sd">        :return: (``int``) total classifications</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_acc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the accuracy</span>

<span class="sd">        :return: (``float``) accuracy</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_correct</span><span class="p">())</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the recall</span>

<span class="sd">        :return: (``float``) recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the precision</span>
<span class="sd">        :return: (``float``) precision</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="n">total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">total</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cm</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_mean_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean precision across labels</span>

<span class="sd">        :return: (``float``) mean precision</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_mean_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the mean recall across labels</span>

<span class="sd">        :return: (``float``) mean recall</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_recall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_weighted_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_total</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_macro_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the macro F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) macro F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_class_f</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_class_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()</span>

        <span class="n">b</span> <span class="o">=</span> <span class="n">beta</span><span class="o">*</span><span class="n">beta</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get 2 class F_b, with adjustable beta (defaulting to F1)</span>

<span class="sd">        :param beta: (``float``) defaults to 1 (F1)</span>
<span class="sd">        :return: (``float``) 2-class F_b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Beta must be greater than 0&#39;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">beta</span><span class="o">*</span><span class="n">beta</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">r</span> <span class="o">/</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">get_all_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Make a map of metrics suitable for reporting, keyed by metric name</span>

<span class="sd">        :return: (``dict``) Map of metrics keyed by metric names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()}</span>
        <span class="c1"># If 2 class, assume second class is positive AKA 1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_precision</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_recall</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;mean_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mean_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;macro_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_macro_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_precision</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_recall</span><span class="p">()</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;weighted_f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weighted_f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">add_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a batch of data to the confusion matrix</span>

<span class="sd">        :param truth: The truth tensor</span>
<span class="sd">        :param guess: The guess tensor</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">guess</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">truth_i</span><span class="p">,</span> <span class="n">guess_i</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span> 
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>       
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">loss_value</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span><span class="p">)</span>
        <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>

<span class="k">class</span> <span class="nc">Evaluator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">y_actual</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">yp</span> <span class="o">=</span> <span class="n">best</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">cm</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">yt</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cm</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">lengths</span><span class="p">,</span> <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_sorted</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sorted</span>

<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">()</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;EPOCH {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;=================================&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation Results&#39;</span><span class="p">)</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;New best model {:.2f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()))</span>
            <span class="n">best_acc</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./checkpoint.pth&#39;</span><span class="p">))</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Final result&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">get_all_metrics</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_acc</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">whitespace_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 

<span class="k">def</span> <span class="nf">sst2_tokenizer</span><span class="p">(</span><span class="n">words</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">REPLACE</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;&#39;s&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;s &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ve&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ve &quot;</span><span class="p">,</span>
                <span class="s2">&quot;n&#39;t&quot;</span><span class="p">:</span> <span class="s2">&quot; n&#39;t &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;re&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;re &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;d&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;d &quot;</span><span class="p">,</span>
                <span class="s2">&quot;&#39;ll&quot;</span><span class="p">:</span> <span class="s2">&quot; &#39;ll &quot;</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="p">:</span> <span class="s2">&quot; , &quot;</span><span class="p">,</span>
                <span class="s2">&quot;!&quot;</span><span class="p">:</span> <span class="s2">&quot; ! &quot;</span><span class="p">,</span>
                <span class="p">}</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^A-Za-z0-9(),!?\&#39;\`]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">REPLACE</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>


<span class="k">class</span> <span class="nc">Reader</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">tokenizer</span><span class="o">=</span><span class="n">sst2_tokenizer</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="o">=</span> <span class="n">lowercase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">build_vocab</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="k">if</span> <span class="n">vectorizer</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">file_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                    <span class="n">y</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                        <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">build_vocab</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cnt</span><span class="p">:</span> <span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_freq</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">alpha</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alpha</span><span class="p">)}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDataset</span><span class="p">:</span>
        <span class="n">label2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">l</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label2index</span><span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lowercase</span> <span class="k">else</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
                <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
                <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec</span><span class="p">))</span>
                <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">lengths_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">lengths_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
</pre></div>


<p>Lets use the trec dataset again</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">dropbox</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="mi">08</span><span class="n">km2ean8bkt7p3</span><span class="o">/</span><span class="n">trec</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">tar</span> <span class="o">-</span><span class="n">xzf</span> <span class="s1">&#39;trec.tar.gz?dl=1&#39;</span>
</pre></div>


<div class="highlight"><pre><span></span>--2019-06-30 00:05:36--  https://www.dropbox.com/s/08km2ean8bkt7p3/trec.tar.gz?dl=1
Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101
Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: /s/dl/08km2ean8bkt7p3/trec.tar.gz [following]
--2019-06-30 00:05:36--  https://www.dropbox.com/s/dl/08km2ean8bkt7p3/trec.tar.gz
Reusing existing connection to www.dropbox.com:443.
HTTP request sent, awaiting response... 302 Found
Location: https://ucc71251671e8209ff817842136f.dl.dropboxusercontent.com/cd/0/get/Ajy7yx6BcLy_D2C847YK2MZsIYRIe4WHUQShODQUsHevIJVdUp_Gu5qxvUTiNpCJ_u89irvfKQJ8E71KrGpT_m0HhXBh79ywpr8iSXN5QO5OpQ/file?dl=1# [following]
--2019-06-30 00:05:37--  https://ucc71251671e8209ff817842136f.dl.dropboxusercontent.com/cd/0/get/Ajy7yx6BcLy_D2C847YK2MZsIYRIe4WHUQShODQUsHevIJVdUp_Gu5qxvUTiNpCJ_u89irvfKQJ8E71KrGpT_m0HhXBh79ywpr8iSXN5QO5OpQ/file?dl=1
Resolving ucc71251671e8209ff817842136f.dl.dropboxusercontent.com (ucc71251671e8209ff817842136f.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106
Connecting to ucc71251671e8209ff817842136f.dl.dropboxusercontent.com (ucc71251671e8209ff817842136f.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 117253 (115K) [application/binary]
Saving to: ‘trec.tar.gz?dl=1’

trec.tar.gz?dl=1    100%[===================&amp;gt;] 114.50K  --.-KB/s    in 0.01s

2019-06-30 00:05:37 (11.3 MB/s) - ‘trec.tar.gz?dl=1’ saved [117253/117253]
</pre></div>


<div class="highlight"><pre><span></span><span class="n">BASE</span> <span class="o">=</span> <span class="s1">&#39;trec&#39;</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.nodev.utf8&#39;</span><span class="p">)</span>
<span class="n">VALID</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.dev.utf8&#39;</span><span class="p">)</span>
<span class="n">TEST</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="s1">&#39;trec.test.utf8&#39;</span><span class="p">)</span>

<span class="c1"># lowercase=False so we can defer to BERT&#39;s tokenizer to handle</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">Reader</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">VALID</span><span class="p">,</span> <span class="n">TEST</span><span class="p">,),</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="n">bert_vectorizer</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">bert_tokenizer</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">)</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">VALID</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">TEST</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">bert_small_dims</span> <span class="o">=</span> <span class="mi">768</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">FineTuneClassifier</span><span class="p">(</span><span class="n">BERT_MODEL</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">bert_small_dims</span><span class="p">)</span>
<span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model has {num_params} parameters&quot;</span><span class="p">)</span> 


<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="n">learnable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learnable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">)</span>

<span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Model has 109486854 parameters
EPOCH 1
=================================
Training Results
{&#39;acc&#39;: 0.8072, &#39;mean_precision&#39;: 0.8136183754170369, &#39;mean_recall&#39;: 0.7346122783828277, &#39;macro_f1&#39;: 0.7542932115362501, &#39;weighted_precision&#39;: 0.8086486190442354, &#39;weighted_recall&#39;: 0.8072, &#39;weighted_f1&#39;: 0.8039545756095884}
Validation Results
{&#39;acc&#39;: 0.8960176991150443, &#39;mean_precision&#39;: 0.836374911050043, &#39;mean_recall&#39;: 0.8982751203248097, &#39;macro_f1&#39;: 0.8490935982370543, &#39;weighted_precision&#39;: 0.9102435016370314, &#39;weighted_recall&#39;: 0.8960176991150443, &#39;weighted_f1&#39;: 0.8940889603495116}
New best model 0.90
EPOCH 2
=================================
Training Results
{&#39;acc&#39;: 0.9592, &#39;mean_precision&#39;: 0.9564446996913963, &#39;mean_recall&#39;: 0.9441293710502765, &#39;macro_f1&#39;: 0.9499487073005133, &#39;weighted_precision&#39;: 0.9591434277886723, &#39;weighted_recall&#39;: 0.9592, &#39;weighted_f1&#39;: 0.9591174670360441}
Validation Results
{&#39;acc&#39;: 0.9446902654867256, &#39;mean_precision&#39;: 0.8878199940761919, &#39;mean_recall&#39;: 0.8917873400275057, &#39;macro_f1&#39;: 0.8895121143056146, &#39;weighted_precision&#39;: 0.9449440203747359, &#39;weighted_recall&#39;: 0.9446902654867256, &#39;weighted_f1&#39;: 0.9445031298581608}
New best model 0.94
EPOCH 3
=================================
Training Results
{&#39;acc&#39;: 0.9784, &#39;mean_precision&#39;: 0.9682000141119786, &#39;mean_recall&#39;: 0.961629040591354, &#39;macro_f1&#39;: 0.9648113009615465, &#39;weighted_precision&#39;: 0.9783229179206641, &#39;weighted_recall&#39;: 0.9784, &#39;weighted_f1&#39;: 0.9783479120110454}
Validation Results
{&#39;acc&#39;: 0.9513274336283186, &#39;mean_precision&#39;: 0.904094720396214, &#39;mean_recall&#39;: 0.9185124935642534, &#39;macro_f1&#39;: 0.9107662900322363, &#39;weighted_precision&#39;: 0.9517688289888032, &#39;weighted_recall&#39;: 0.9513274336283186, &#39;weighted_f1&#39;: 0.9514516397598308}
New best model 0.95
EPOCH 4
=================================
Training Results
{&#39;acc&#39;: 0.9878, &#39;mean_precision&#39;: 0.9879920250105357, &#39;mean_recall&#39;: 0.9803402721232928, &#39;macro_f1&#39;: 0.9840564690593671, &#39;weighted_precision&#39;: 0.9877906525358927, &#39;weighted_recall&#39;: 0.9878, &#39;weighted_f1&#39;: 0.987783074278954}
Validation Results
{&#39;acc&#39;: 0.9469026548672567, &#39;mean_precision&#39;: 0.8920679986535167, &#39;mean_recall&#39;: 0.9123880140014059, &#39;macro_f1&#39;: 0.9004386136056346, &#39;weighted_precision&#39;: 0.9489356221151654, &#39;weighted_recall&#39;: 0.9469026548672567, &#39;weighted_f1&#39;: 0.9476173076771826}
EPOCH 5
=================================
Training Results
{&#39;acc&#39;: 0.9904, &#39;mean_precision&#39;: 0.9904490381789716, &#39;mean_recall&#39;: 0.9862979863492165, &#39;macro_f1&#39;: 0.9883441530923012, &#39;weighted_precision&#39;: 0.9904177347691059, &#39;weighted_recall&#39;: 0.9904, &#39;weighted_f1&#39;: 0.9904029148588175}
Validation Results
{&#39;acc&#39;: 0.922566371681416, &#39;mean_precision&#39;: 0.8451025054934176, &#39;mean_recall&#39;: 0.9188274343553847, &#39;macro_f1&#39;: 0.8614088235624355, &#39;weighted_precision&#39;: 0.9374259585988132, &#39;weighted_recall&#39;: 0.922566371681416, &#39;weighted_f1&#39;: 0.9265075358706969}
EPOCH 6
=================================
Training Results
{&#39;acc&#39;: 0.9928, &#39;mean_precision&#39;: 0.9849192613386126, &#39;mean_recall&#39;: 0.9903185624313342, &#39;macro_f1&#39;: 0.9875625640550693, &#39;weighted_precision&#39;: 0.9928298071879748, &#39;weighted_recall&#39;: 0.9928, &#39;weighted_f1&#39;: 0.9928084053080909}
Validation Results
{&#39;acc&#39;: 0.9513274336283186, &#39;mean_precision&#39;: 0.893967686997322, &#39;mean_recall&#39;: 0.9183550231686878, &#39;macro_f1&#39;: 0.9044542863397047, &#39;weighted_precision&#39;: 0.952784511352824, &#39;weighted_recall&#39;: 0.9513274336283186, &#39;weighted_f1&#39;: 0.951835857546077}
EPOCH 7
=================================
Training Results
{&#39;acc&#39;: 0.9876, &#39;mean_precision&#39;: 0.9804630124660259, &#39;mean_recall&#39;: 0.9841335871628117, &#39;macro_f1&#39;: 0.9822722690431217, &#39;weighted_precision&#39;: 0.9876262764090674, &#39;weighted_recall&#39;: 0.9876, &#39;weighted_f1&#39;: 0.9876091385818745}
Validation Results
{&#39;acc&#39;: 0.9358407079646017, &#39;mean_precision&#39;: 0.869223467111762, &#39;mean_recall&#39;: 0.8845714614348155, &#39;macro_f1&#39;: 0.8760358467213519, &#39;weighted_precision&#39;: 0.9368478438194213, &#39;weighted_recall&#39;: 0.9358407079646017, &#39;weighted_f1&#39;: 0.935724397414086}
EPOCH 8
=================================
Training Results
{&#39;acc&#39;: 0.9882, &#39;mean_precision&#39;: 0.9884659041101195, &#39;mean_recall&#39;: 0.9867900044940896, &#39;macro_f1&#39;: 0.9876206331590174, &#39;weighted_precision&#39;: 0.9881936208229168, &#39;weighted_recall&#39;: 0.9882, &#39;weighted_f1&#39;: 0.9881954635511713}
Validation Results
{&#39;acc&#39;: 0.9358407079646017, &#39;mean_precision&#39;: 0.8653465960956793, &#39;mean_recall&#39;: 0.881882140940112, &#39;macro_f1&#39;: 0.8719854535151271, &#39;weighted_precision&#39;: 0.9377869080790039, &#39;weighted_recall&#39;: 0.9358407079646017, &#39;weighted_f1&#39;: 0.9363262436397539}
EPOCH 9
=================================
Training Results
{&#39;acc&#39;: 0.9948, &#39;mean_precision&#39;: 0.9938950329200654, &#39;mean_recall&#39;: 0.995900483358696, &#39;macro_f1&#39;: 0.9948909466726953, &#39;weighted_precision&#39;: 0.9948017988410376, &#39;weighted_recall&#39;: 0.9948, &#39;weighted_f1&#39;: 0.9947999511094636}
Validation Results
{&#39;acc&#39;: 0.9535398230088495, &#39;mean_precision&#39;: 0.9109100734862207, &#39;mean_recall&#39;: 0.8984192710900785, &#39;macro_f1&#39;: 0.9035579458427662, &#39;weighted_precision&#39;: 0.9539677301282238, &#39;weighted_recall&#39;: 0.9535398230088495, &#39;weighted_f1&#39;: 0.9530178469339025}
New best model 0.95
EPOCH 10
=================================
Training Results
{&#39;acc&#39;: 0.9954, &#39;mean_precision&#39;: 0.995972032266384, &#39;mean_recall&#39;: 0.99609205194803, &#39;macro_f1&#39;: 0.9960309853717155, &#39;weighted_precision&#39;: 0.9954031919811314, &#39;weighted_recall&#39;: 0.9954, &#39;weighted_f1&#39;: 0.9954004886293786}
Validation Results
{&#39;acc&#39;: 0.9380530973451328, &#39;mean_precision&#39;: 0.8994923889440322, &#39;mean_recall&#39;: 0.8819619949625506, &#39;macro_f1&#39;: 0.8895000197629823, &#39;weighted_precision&#39;: 0.9389177796726109, &#39;weighted_recall&#39;: 0.9380530973451328, &#39;weighted_f1&#39;: 0.9377173424408575}
EPOCH 11
=================================
Training Results
{&#39;acc&#39;: 0.9928, &#39;mean_precision&#39;: 0.9940289451739184, &#39;mean_recall&#39;: 0.9938861281254447, &#39;macro_f1&#39;: 0.9939570832728007, &#39;weighted_precision&#39;: 0.992803497450866, &#39;weighted_recall&#39;: 0.9928, &#39;weighted_f1&#39;: 0.992801187319044}
Validation Results
{&#39;acc&#39;: 0.9358407079646017, &#39;mean_precision&#39;: 0.8802438200074015, &#39;mean_recall&#39;: 0.8827911745872409, &#39;macro_f1&#39;: 0.8809691508186295, &#39;weighted_precision&#39;: 0.9370109437460447, &#39;weighted_recall&#39;: 0.9358407079646017, &#39;weighted_f1&#39;: 0.9356818495736176}
EPOCH 12
=================================
Training Results
{&#39;acc&#39;: 0.9964, &#39;mean_precision&#39;: 0.9968305108450592, &#39;mean_recall&#39;: 0.9968291018285336, &#39;macro_f1&#39;: 0.996829742211563, &#39;weighted_precision&#39;: 0.9964006985237956, &#39;weighted_recall&#39;: 0.9964, &#39;weighted_f1&#39;: 0.9964002616562497}
Validation Results
{&#39;acc&#39;: 0.9402654867256637, &#39;mean_precision&#39;: 0.8849039337406327, &#39;mean_recall&#39;: 0.8855626535491959, &#39;macro_f1&#39;: 0.8850671576152163, &#39;weighted_precision&#39;: 0.9401396828339421, &#39;weighted_recall&#39;: 0.9402654867256637, &#39;weighted_f1&#39;: 0.9400061909300451}
Final result
{&#39;acc&#39;: 0.968, &#39;mean_precision&#39;: 0.9599401688044865, &#39;mean_recall&#39;: 0.9541044368804091, &#39;macro_f1&#39;: 0.9566602649716377, &#39;weighted_precision&#39;: 0.9685049225387307, &#39;weighted_recall&#39;: 0.968, &#39;weighted_f1&#39;: 0.967793480357041}





0.968
</pre></div>


<p>We can see that this is a <em>massive</em> gain over our CNN baseline and also improves over our ELMo contextual embeddings for this dataset.  BERT has been shown high-performance results across many datasets, and integrating it into unstructured prediction problems is quite simple, as we saw in this section.</p>
<h2>Conclusion</h2>
<p>In this section we investigated the Transformer model architecture, particularly in the context of pretraining LMs.  We discussed some of the model details and we looked at how BERT extends the GPT approach from OpenAI.  We then built our own fine-tuned classifier using the Hugging Face PyTorch library to create and re-load the BERT model and add our own layers on top.</p>
<h3>Some further resources</h3>
<p>We have only scratched the surface of the exciting way that transfer learning is transforming NLP. </p>
<ul>
<li><strong>Transformer Architecture</strong></li>
<li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a>: mentioned previously, but so good it deserves mentioning again</li>
<li><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>:  good tutorial on how the Transformer works</li>
<li>
<p>A really nice blogpost on transfer learning from Sebastian Ruder (http://ruder.io/nlp-imagenet/)</p>
</li>
<li>
<p><strong>Transfer Learning</strong></p>
</li>
<li>A <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit">fantastic tutorial at NAACL this year</a> which is both thorough and introductory.  It covers a lot of material including how to probe pretrain models to try and figure out what they are up to</li>
<li>
<p>A nice colab from the Google BERT devs showing using BERT from TF-Hub (https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb)</p>
</li>
<li>
<p><strong>Model Intepretation and Probing</strong></p>
</li>
<li>Jesse Vig's Blog post analyzing the different heads of BERT based<ul>
<li>Part I: https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77</li>
<li>Part II: https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1</li>
<li>And a colab that drills into the <a href="https://colab.research.google.com/drive/1Nlhh2vwlQdKleNMqpmLDBsAwrv_7NnrB">Q and K vectors during multi-head attention here</a>: </li>
</ul>
</li>
<li><a href="https://github.com/clarkkev/attention-analysis">Kevin Clark's Jupyter Notebooks</a> for <a href="https://arxiv.org/abs/1906.04341">What Does BERT Look At? An Analysis of BERT's Attention, Clark et al., 2019</a></li>
<li><a href="https://github.com/TalLinzen/rnn_agreement">Tal Linzen's code</a> for <a href="https://arxiv.org/abs/1611.01368">Assessing the ability of LSTMs to learn syntax-sensitive dependencies, Linzen et al., 2016</a></li>
<li><a href="https://github.com/yoavg/bert-syntax">Yoav Goldberg's code</a> assessing syntactic abilities of BERT</li>
<li>
<p><a href="https://github.com/nelson-liu/contextual-repr-analysis">Nelson Liu's code</a> for <a href="https://homes.cs.washington.edu/~nfliu/papers/liu+gardner+belinkov+peters+smith.naacl2019.pdf">Linguistic Knowledge and Transferability of Contextual Representations, Liu et al., 2019</a></p>
</li>
<li>
<p><strong>More about Neural NLP</strong></p>
</li>
<li>
<p>Get right into the source material.  Some papers that are helpful to understand deep learning in NLP (https://github.com/dpressel/lit)</p>
</li>
<li>
<p><strong>Get Hacking</strong></p>
</li>
<li>Implementations of most of what we talked about today in TensorFlow and PyTorch (https://github.com/dpressel/baseline)</li>
</ul>
<p>There is also an end-to-end example using the Baseline API above to train a GPT-like LM using the code above in PyTorch:</p>
<p>https://github.com/dpressel/baseline/blob/master/api-examples/pretrain-transformer-lm.py</p>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "leafyleap-2"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Mohcine Madkour &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>