#AUTOGENERATED! DO NOT EDIT! file to edit: ./TSTrain.ipynb (unless otherwise specified)

try:
    from exp.nb_TSUtilities import *
    from exp.nb_TSBasicData import *
    from exp.nb_TSDatasets import *

except ImportError:
    from .nb_TSUtilities import *
    from .nb_TSBasicData import *
    from .nb_TSDatasets import *

import time


def create_UCR_databunch(dsid, bs=64, scale_type='standardize', scale_subtype='per_channel',
                         scale_range =(-1, 1), cpus=defaults.cpus, device=defaults.device, verbose=False):
    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, verbose=verbose)
    db = (ItemLists('.', TimeSeriesList(X_train), TimeSeriesList(X_valid))
          .label_from_lists(y_train, y_valid)
          .databunch(bs=min(bs, len(X_train)), val_bs=min(len(X_valid), bs * 2), num_workers=cpus, device=device)
          .scale(scale_type=scale_type, scale_subtype=scale_subtype, scale_range=scale_range)
         )
    return db


def run_UCR_test(iters, epochs, datasets, arch,
                 bs=64, max_lr=3e-3, pct_start=.7, warmup=False, wd=1e-2,
                 metrics=[accuracy], mixup=False,
                 scale_type ='standardize', scale_subtype='per_channel', scale_range=(-1, 1),
                 opt_func=functools.partial(torch.optim.Adam, betas=(0.9, 0.99)),
                 loss_func=None, **arch_kwargs):
    ds_, acc_, acces_, accmax_, iter_, time_, epochs_, loss_, val_loss_   = [], [], [], [], [], [], [], [], []
    datasets = listify(datasets)
    for ds in datasets:
        db = create_UCR_databunch(ds)
        for i in range(iters):
            print('\n', ds, i)
            ds_.append(ds)
            iter_.append(i)
            epochs_.append(epochs)
            model = arch(db.features, db.c, **arch_kwargs).to(defaults.device)
            learn = Learner(db, model, opt_func=opt_func, loss_func=loss_func)
            if mixup: learn.mixup()
            learn.metrics = metrics
            start_time = time.time()
            learn.fit_one_cycle(epochs, max_lr=max_lr, pct_start=pct_start, moms=(.95, .85) if warmup else (.95, .95),
                                div_factor=25.0 if warmup else 1., wd=wd)
            duration = time.time() - start_time
            time_.append('{:.0f}'.format(duration))
            early_stop = math.ceil(np.argmin(learn.recorder.losses) / len(learn.data.train_dl))
            acc_.append(learn.recorder.metrics[-1][0].item())
            acces_.append(learn.recorder.metrics[early_stop - 1][0].item())
            accmax_.append(np.max(learn.recorder.metrics))
            loss_.append(learn.recorder.losses[-1].item())
            val_loss_.append(learn.recorder.val_losses[-1].item())
            if len(datasets) * iters >1: clear_output()
            df = (pd.DataFrame(np.stack((ds_, iter_, epochs_, loss_, val_loss_ ,acc_, acces_, accmax_, time_)).T,
                               columns=['dataset', 'iter', 'epochs', 'loss', 'val_loss',
                                        'accuracy', 'accuracy_ts',
                                        'max_accuracy', 'time (s)'])
                  )
            df = df.astype({'loss': float, 'val_loss': float, 'accuracy': float,
                            'accuracy_ts': float, 'max_accuracy': float})
            display(df)
    return learn, df